{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ACD_Not_Process.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d5de164eace14e13aa1b9fae08c4043b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_101cc32a50084d5da86fe7991867aed5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8c018382781646f2924e2b8964c6d29a","IPY_MODEL_2aa740b2b2b94f1ca88f4a2f29f2312e"]}},"101cc32a50084d5da86fe7991867aed5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c018382781646f2924e2b8964c6d29a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0b2c5d0a5b844c6f9e0aacec9f2cb6f4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d0a51b323ffb44879292d8bab08fe3d2"}},"2aa740b2b2b94f1ca88f4a2f29f2312e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_848dee7e7dbf4aa1937996aa5a69fc54","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:31&lt;00:00, 19.6B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_909cc115f8b24298940a6d98e2453056"}},"0b2c5d0a5b844c6f9e0aacec9f2cb6f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d0a51b323ffb44879292d8bab08fe3d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"848dee7e7dbf4aa1937996aa5a69fc54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"909cc115f8b24298940a6d98e2453056":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2b3081f8e7942f0b4d94af1d4e1f4ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_35c7cc20bd18424b86d0477e676ef182","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9808684fe55845c3a54c2ed790c88199","IPY_MODEL_8500f29e8b53461d80ec46b59fc3f896"]}},"35c7cc20bd18424b86d0477e676ef182":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9808684fe55845c3a54c2ed790c88199":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3c99912d82b74d0dbd39e92e3d495cfc","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9e3fe5b0cdeb47ea9bb1d984565890e8"}},"8500f29e8b53461d80ec46b59fc3f896":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a54d6e87554b423bb048ef159e3d4a3e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 714M/714M [00:31&lt;00:00, 22.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e302e9fc10645cb988d6c9af3d7fe0e"}},"3c99912d82b74d0dbd39e92e3d495cfc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9e3fe5b0cdeb47ea9bb1d984565890e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a54d6e87554b423bb048ef159e3d4a3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1e302e9fc10645cb988d6c9af3d7fe0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"80cc3a3c074e424bb05783af878b2564":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_20953bf31aa54eb995a31ff2733ef618","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c559b74c6ab049559250b6d713cbcc4a","IPY_MODEL_f410661348914cdbbfd6489c778ca174"]}},"20953bf31aa54eb995a31ff2733ef618":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c559b74c6ab049559250b6d713cbcc4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_eb03bfdbf1e04baba13fceac1d6c04ab","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fcbac16a9b9e4c8392a0a1ab1b478f7e"}},"f410661348914cdbbfd6489c778ca174":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_61b9521b02f5432baf21f62a1ba97b2f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:00&lt;00:00, 30.5B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fea18549e89d49c58846410daa1169fe"}},"eb03bfdbf1e04baba13fceac1d6c04ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fcbac16a9b9e4c8392a0a1ab1b478f7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61b9521b02f5432baf21f62a1ba97b2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fea18549e89d49c58846410daa1169fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b745beea706470da60978a219922286":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fc5509034e8c462a8da35ee8c4d6de22","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3bea8e9e14ec45d598c55daf2fd47477","IPY_MODEL_5aab5fb1da04407b94e7be17c464c71a"]}},"fc5509034e8c462a8da35ee8c4d6de22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3bea8e9e14ec45d598c55daf2fd47477":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8b62ac6d39af4756bb22b959e3ff8801","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_faafa8800c9e4fe29f7aa1bde82d0291"}},"5aab5fb1da04407b94e7be17c464c71a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f837738530154272ae7ee47dbcd01e6c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:14&lt;00:00, 70.6kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c7e0e2b561c44ad795576112d80c0b77"}},"8b62ac6d39af4756bb22b959e3ff8801":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"faafa8800c9e4fe29f7aa1bde82d0291":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f837738530154272ae7ee47dbcd01e6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c7e0e2b561c44ad795576112d80c0b77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67192bac395a4c9198c3853f43dfe34b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_45023450f53347609a1155b588be592c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3f7178cbdf9b4a06999789541ee42f87","IPY_MODEL_22de8dc868404d0d9090a1a5518239a3"]}},"45023450f53347609a1155b588be592c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f7178cbdf9b4a06999789541ee42f87":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b74c1b71c68448318e19861f332c04a0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1961828,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1961828,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b4e3950f416414295b3cbb486e9bab1"}},"22de8dc868404d0d9090a1a5518239a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_63182909251b404586bde5af2f1541c4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.96M/1.96M [00:13&lt;00:00, 148kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef30d9eafc6747eea72d90c6f2c42120"}},"b74c1b71c68448318e19861f332c04a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3b4e3950f416414295b3cbb486e9bab1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"63182909251b404586bde5af2f1541c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ef30d9eafc6747eea72d90c6f2c42120":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4b2789d5b1c1441c93cfc51a7d6f3715":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_458cd8ff00054aa2b5494d0fc1f205f6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d577b6dccab04f2590652f582e95af45","IPY_MODEL_72317bf812354443b095f903fd40053e"]}},"458cd8ff00054aa2b5494d0fc1f205f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d577b6dccab04f2590652f582e95af45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_abc4e38cb8e742a4a6fb7c8dbc1bcd53","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1403,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1403,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_070a2f2614da40638357f3d672960cfc"}},"72317bf812354443b095f903fd40053e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_270e00616f6042f69be29e9f7ae3b793","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.40k/1.40k [00:16&lt;00:00, 84.6B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0c09c07eec9149838b36ce460ef3fe09"}},"abc4e38cb8e742a4a6fb7c8dbc1bcd53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"070a2f2614da40638357f3d672960cfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"270e00616f6042f69be29e9f7ae3b793":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0c09c07eec9149838b36ce460ef3fe09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ad22718cc81540828304f8eaaa2745f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_353b390f87494538af63332828c83942","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_074f7670412948baa84391ad4cb3190c","IPY_MODEL_7cdf6b52c33447399d08082b771340f4"]}},"353b390f87494538af63332828c83942":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"074f7670412948baa84391ad4cb3190c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c32f53ee020e46f89d68b8c177b7bae2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":581243664,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":581243664,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_444784ccef004664baa27e2b529c0edf"}},"7cdf6b52c33447399d08082b771340f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4547660b5be64960aad6e2d7b8888c7b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 581M/581M [00:16&lt;00:00, 35.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_97a0a9e0d5d34e89afcf8d03631bb81b"}},"c32f53ee020e46f89d68b8c177b7bae2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"444784ccef004664baa27e2b529c0edf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4547660b5be64960aad6e2d7b8888c7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"97a0a9e0d5d34e89afcf8d03631bb81b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57600fabe0e841ce86e10ef35572d25d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4d01ac54670f49c790fb2c2020f0dfa0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7cfd5be3cf3e4756b519c4365619d00d","IPY_MODEL_1b6225bedc39450eb3703d44124d0659"]}},"4d01ac54670f49c790fb2c2020f0dfa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7cfd5be3cf3e4756b519c4365619d00d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ab7ee9b99a3c4149980d96c2a2225ddf","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":254703,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":254703,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_52750ff035f04df9ae93cc51ae68d9f5"}},"1b6225bedc39450eb3703d44124d0659":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_12e4f29a59144cd4af0fe7cf026f9ae6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 255k/255k [00:00&lt;00:00, 1.36MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2afebcd02ebd442480fab37213e06308"}},"ab7ee9b99a3c4149980d96c2a2225ddf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"52750ff035f04df9ae93cc51ae68d9f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"12e4f29a59144cd4af0fe7cf026f9ae6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2afebcd02ebd442480fab37213e06308":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d245d17206f840f0bb7401aef37f4e6c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_31eef4459e104536aec796ea09be9a49","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a0956a6f0ef14745ae22165a8a47df43","IPY_MODEL_fb490e5a97df4e82b5ebff2d4d3bc014"]}},"31eef4459e104536aec796ea09be9a49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a0956a6f0ef14745ae22165a8a47df43":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_51d67c00686b4386b3d0bd6485b52c3a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":557,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":557,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_92a1c3ca15c24882bb04be49b3fb34a5"}},"fb490e5a97df4e82b5ebff2d4d3bc014":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5753d14430524a61addb19d5ee1d70fa","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 557/557 [00:00&lt;00:00, 2.74kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a916dff565804e0fb11940fe838d2ead"}},"51d67c00686b4386b3d0bd6485b52c3a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"92a1c3ca15c24882bb04be49b3fb34a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5753d14430524a61addb19d5ee1d70fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a916dff565804e0fb11940fe838d2ead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7094a2be6b174e8f98d27d34fca2b462":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d47944c684674afca2c47361f2a88060","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_30ddb1112fb24abe968387c198a62a4a","IPY_MODEL_3a71f33cc8c642d5902e42e99619e18a"]}},"d47944c684674afca2c47361f2a88060":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30ddb1112fb24abe968387c198a62a4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d9ff860cfd1b416fad11e6ed2262ac42","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":542923308,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":542923308,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e1a075005c54f8181ce026cc68c5342"}},"3a71f33cc8c642d5902e42e99619e18a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_26348156ca8c4b07b56156ed863ec236","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 543M/543M [00:12&lt;00:00, 42.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7dd8674cbe084d04bb9ec06c35b1660b"}},"d9ff860cfd1b416fad11e6ed2262ac42":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1e1a075005c54f8181ce026cc68c5342":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26348156ca8c4b07b56156ed863ec236":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7dd8674cbe084d04bb9ec06c35b1660b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"36518c63379f4b7ea87f5978472410c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e349d8b8fb454e66be5c005389aa0202","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_31633536071646478d235ea1ce257a2e","IPY_MODEL_701575875e924f0fa523a6f728df5b2e"]}},"e349d8b8fb454e66be5c005389aa0202":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31633536071646478d235ea1ce257a2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0b78ff6ab4144db68092aa34bf4334b3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":895321,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":895321,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a0319354e8d40f5bd1c53a872d27c95"}},"701575875e924f0fa523a6f728df5b2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_38b57d9f12f24466a526bb7e0d79dd0b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 895k/895k [00:00&lt;00:00, 2.29MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c90df9743e234a198b9a6da376e495c4"}},"0b78ff6ab4144db68092aa34bf4334b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5a0319354e8d40f5bd1c53a872d27c95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"38b57d9f12f24466a526bb7e0d79dd0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c90df9743e234a198b9a6da376e495c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b22b22fc26f4824a9e7c5abf4861e19":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aaaad4f481c04bef8a2bbefe70ca1d96","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_202b60fb9903403095f09f2c9c1e0a0c","IPY_MODEL_36417ee4b07840839365e5196710153a"]}},"aaaad4f481c04bef8a2bbefe70ca1d96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"202b60fb9903403095f09f2c9c1e0a0c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_24e761703bb24ef3afff084e71969972","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1135173,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1135173,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75862d3ac7874382aeddfcf888af44b8"}},"36417ee4b07840839365e5196710153a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d1fd8d0616e64dc7863a3ec72de9a2fc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.14M/1.14M [00:00&lt;00:00, 4.32MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c68c1f1b4ce748e2bd019dcc16a28491"}},"24e761703bb24ef3afff084e71969972":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"75862d3ac7874382aeddfcf888af44b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1fd8d0616e64dc7863a3ec72de9a2fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c68c1f1b4ce748e2bd019dcc16a28491":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"Y1tj4Qe9I7pd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625057702140,"user_tz":-420,"elapsed":8825,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"0640c3e9-2aae-45a1-92d0-c664d864ad00"},"source":["!pip install scikit-multilearn\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting scikit-multilearn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n","\r\u001b[K     |███▊                            | 10kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 19.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 5.5MB/s \n","\u001b[?25hInstalling collected packages: scikit-multilearn\n","Successfully installed scikit-multilearn-0.2.0\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 7.5MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 46.5MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Collecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 47.8MB/s \n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vxc32d7drrmc","executionInfo":{"status":"ok","timestamp":1625057702142,"user_tz":-420,"elapsed":69,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"e42193f4-f1b8-4dc1-e45e-526b61f781af"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bHW4hGIHI9Wp"},"source":["# Thư viện"]},{"cell_type":"code","metadata":{"id":"exk1LKxTIfJj"},"source":["from numpy import mean\n","from numpy import std\n","from sklearn.datasets import make_multilabel_classification\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import StratifiedShuffleSplit\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from gensim.models import KeyedVectors\n","import pandas as pd\n","import numpy as np\n","from sklearn.naive_bayes import ComplementNB\n","import seaborn as sb\n","import matplotlib.pyplot as plt\n","from gensim.models import Word2Vec\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import re\n","import joblib\n","import nltk\n","from sklearn.multioutput import MultiOutputClassifier\n","\n","from nltk.tokenize import TweetTokenizer\n","from bs4 import BeautifulSoup\n","from nltk.stem.porter import PorterStemmer\n","from sklearn.naive_bayes import GaussianNB\n","from skmultilearn.problem_transform import BinaryRelevance\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.multiclass import OneVsRestClassifier\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.models import Sequential\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Embedding, Conv1D, GlobalMaxPool1D, Dense, Flatten, Dropout, GRU, Bidirectional\n","\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n","from sklearn.metrics import f1_score\n","import pandas as pd\n","import re\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.svm import SVC\n","from sklearn.multiclass import OneVsRestClassifier\n","from keras.models import load_model\n","from joblib import dump\n","import torch\n","import pandas as pd\n","import numpy as np\n","\n","# Thu vien transformer cho Classification\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, BertTokenizer, BertForSequenceClassification\n","\n","# Xu ly label\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Metric danh gia \n","from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n","\n","# Ve do thi\n","import seaborn as sn\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ZSMSY1g1Txv"},"source":["# Đọc dữ liệu"]},{"cell_type":"code","metadata":{"id":"wq7Z-Nvt1Txw","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"ok","timestamp":1625057712223,"user_tz":-420,"elapsed":1948,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"ee1dbca3-530f-418c-d83e-2f3377d20ac5"},"source":["df_train = pd.read_csv('/content/drive/MyDrive/NLP for Data Science/NLP_Project/Data_csv/ACD_data/ACD_train.csv')\n","df_dev = pd.read_csv('/content/drive/MyDrive/NLP for Data Science/NLP_Project/Data_csv/ACD_data/ACD_dev.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/NLP for Data Science/NLP_Project/Data_csv/ACD_data/ACD_test.csv')\n","\n","df_train.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>aspect</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Giá 53k size vừa.</td>\n","      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Nhưng nói chung cũng hơi đắt.</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Mình ăn rất hôi mùi dầu.</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Mình ăn chưa baoh thấy mùi hôi hải sản.</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3 dĩa vs 2 lon Revive mà có 190k thui(.</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Ở đây ngay khu vắng nên khách cũng không đông ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Quán đông lắm, gọi món phải đợi hơi lâu, ko bi...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Mình uống trà sữa lài hạnh nhân khá thơm nha, ...</td>\n","      <td>[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Không gian trang trí đơn giàn mà ấm cúng, nên ...</td>\n","      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Chè lạnh thì hình như lúc nào cũng là sương sa...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             comment                                aspect\n","0                                  Giá 53k size vừa.  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n","1                      Nhưng nói chung cũng hơi đắt.  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n","2                           Mình ăn rất hôi mùi dầu.  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","3            Mình ăn chưa baoh thấy mùi hôi hải sản.  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","4            3 dĩa vs 2 lon Revive mà có 190k thui(.  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n","5  Ở đây ngay khu vắng nên khách cũng không đông ...  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","6  Quán đông lắm, gọi món phải đợi hơi lâu, ko bi...  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n","7  Mình uống trà sữa lài hạnh nhân khá thơm nha, ...  [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n","8  Không gian trang trí đơn giàn mà ấm cúng, nên ...  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","9  Chè lạnh thì hình như lúc nào cũng là sương sa...  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"pZ6Xsgk81Txx"},"source":["# Chuyển aspect từ string sang list\n","def astype_aspect(df):\n","    for i in range(len(df)):\n","        aspect = df['aspect'][i][1:-1]\n","        aspect = aspect.split(\", \")\n","        df['aspect'][i] = (list(map(int, aspect)))\n","    return df\n","\n","df_train = astype_aspect(df_train)\n","df_dev = astype_aspect(df_dev)\n","df_test = astype_aspect(df_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W2q4-FwI1Txy"},"source":["# X và y"]},{"cell_type":"code","metadata":{"id":"_MZaohpk1Txy"},"source":["X_train = df_train['comment'].values\n","X_dev = df_dev['comment'].values\n","X_test = df_test['comment'].values\n","\n","y_train = df_train['aspect'].values\n","y_dev = df_dev['aspect'].values\n","y_test = df_test['aspect'].values\n","\n","y_train = np.array(list(y_train), dtype=np.float)\n","y_dev = np.array(list(y_dev), dtype=np.float)\n","y_test = np.array(list(y_test), dtype=np.float)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7kyR3lOv1Txz","colab":{"base_uri":"https://localhost:8080/","height":648},"executionInfo":{"status":"ok","timestamp":1625057714842,"user_tz":-420,"elapsed":1742,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"09f632b8-76c4-4a59-ec8c-02a396f955fb"},"source":["# Độ dài cmt\n","def plot_number_word(X, name):\n","    l = []\n","    for i in range(len(X)):\n","        l.append(len(X[i].split()))\n","    plt.figure(figsize = (15, 2))\n","    sns.countplot(l)\n","    plt.title(\"Number of words in comment in \" + name + ' dataset.')\n","    plt.xlabel(\"Number of words\")\n","    plt.ylabel(\"Frequency\")\n","    plt.show()\n","\n","plot_number_word(X_train, 'train')\n","plot_number_word(X_dev, 'dev')\n","plot_number_word(X_test, 'test')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1080x144 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1080x144 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1080x144 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"raY9jST81Txy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625057714843,"user_tz":-420,"elapsed":18,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"2b9e05d0-fbf9-4fc1-cca3-ad3f5084823c"},"source":["X_train[:3]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Giá 53k size vừa.', 'Nhưng nói chung cũng hơi đắt.',\n","       'Mình ăn rất hôi mùi dầu.'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"Z2Rx70fR1Txz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625057714844,"user_tz":-420,"elapsed":17,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"01c789b8-61e7-420c-8c42-f0b839b8c742"},"source":["y_train[:3]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"6Ok7HRWjHjVn"},"source":["# Check word in Embedding"]},{"cell_type":"markdown","metadata":{"id":"6ICNpsdRMlob"},"source":["# No Process\n","fastText : \n","*   Have(4259)\n","*   No(522)\n","\n","multi: \n","* Have(2268)\n","* No(2513)\n","\n","wiki: \n","* Have(3549)\n","* No(1232)\n","\n","bpemb: \n","* Have(2815)\n","* No(1966)"]},{"cell_type":"markdown","metadata":{"id":"4l5nwbDSE6E2"},"source":["# ================================================================"]},{"cell_type":"code","metadata":{"id":"IY6UTn5lXKC9"},"source":["model_name = [\"Native Bayes\",\n","              \"Logistic Regression\",\n","              \"SVM\",\n","              \"Text-CNN-fastText\",\n","              \"Text-CNN-Wikipedia Word2vec\",\n","              \"Text-CNN-BPEmb\",\n","              \"Text-CNN-MULTI_WC_F_E_B\",\n","              \"Bi-GRU-fastText\",\n","              \"Bi-GRU-Wikipedia Word2vec\",\n","              \"Bi-GRU-BPEmb\",\n","              \"Bi-GRU-MULTI_WC_F_E_B\",\n","              \"BERT XLM-R\",\n","              \"BERT MULTILINGUAL\"\n","              \"FPTAI (cased)\",\n","              \"PhoBERT\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mlBZOPvx9nvY"},"source":["# Model---Naive Bayes"]},{"cell_type":"code","metadata":{"id":"R7b8_VKK9vU9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624968864398,"user_tz":-420,"elapsed":105600,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"d505e408-1c1d-4a22-e831-d1e5d5a4f0bd"},"source":["tv = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3))\n","x_train = tv.fit_transform(X_train)\n","x_dev = tv.transform(X_dev)\n","x_test = tv.transform(X_test)\n","\n","model = BinaryRelevance(ComplementNB())\n","model.fit(x_train, y_train)\n","\n","y_train_pred = model.predict(x_train)\n","y_dev_pred = model.predict(x_dev)\n","y_test_pred = model.predict(x_test)\n","\n","acc_train = accuracy_score(y_train, y_train_pred)\n","acc_dev = accuracy_score(y_dev, y_dev_pred)\n","acc_test = accuracy_score(y_test, y_test_pred)\n","f1_macro_test = f1_score(y_test, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","# Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[0]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                    \"PRECISION-MICRO\": [precision_micro_test], \n","                    \"RECALL-MICRO\":[recall_micro_test],\n","                    \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",\n","          index = None, header = True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["=================================================================================\n","Accuracy train:  0.6014513375071144\n","Accuracy dev:  0.20492866407263294\n","Accuracy test:  0.19917440660474717\n","F1 macro test:  0.2418553508463007\n","Recall macro test:  0.15798649572585136\n","Precision macro test:  0.7686096658155481\n","F1 micro test:  0.3677673432293245\n","Recall micro test:  0.23088626854317232\n","Precision micro test:  0.9032738095238095\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l4URVO6L9_9e"},"source":["# Model---Logistic Regression"]},{"cell_type":"code","metadata":{"id":"G-NxdmvH-FhW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624968876045,"user_tz":-420,"elapsed":11232,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"f8fa9960-a97b-4187-8bf4-e45cf0a2b069"},"source":["tv = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3))\n","x_train = tv.fit_transform(X_train)\n","x_dev = tv.transform(X_dev)\n","x_test = tv.transform(X_test)\n","\n","model = MultiOutputClassifier(LogisticRegression())\n","model.fit(x_train, y_train)\n","\n","y_train_pred = model.predict(x_train)\n","y_dev_pred = model.predict(x_dev)\n","y_test_pred = model.predict(x_test)\n","\n","acc_train = accuracy_score(y_train, y_train_pred)\n","acc_dev = accuracy_score(y_dev, y_dev_pred)\n","acc_test = accuracy_score(y_test, y_test_pred)\n","f1_macro_test = f1_score(y_test, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[1]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["=================================================================================\n","Accuracy train:  0.39314171883893\n","Accuracy dev:  0.3631647211413748\n","Accuracy test:  0.37100103199174406\n","F1 macro test:  0.44595625330793975\n","Recall macro test:  0.34165368460731665\n","Precision macro test:  0.7420852703968697\n","F1 micro test:  0.6032689450222882\n","Recall micro test:  0.46329402814758464\n","Precision micro test:  0.8644428672817601\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"7h0tMt5MQFpa"},"source":["# Model---SVM"]},{"cell_type":"code","metadata":{"id":"JEqSVn7AOrwD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624969116147,"user_tz":-420,"elapsed":240138,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"a4a252a7-e2c2-40f3-afd9-33d0208f3dca"},"source":["tv = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3))\n","x_train = tv.fit_transform(X_train)\n","x_dev = tv.transform(X_dev)\n","x_test = tv.transform(X_test)\n","\n","model = MultiOutputClassifier(SVC())\n","model.fit(x_train, y_train)\n","\n","y_train_pred = model.predict(x_train)\n","y_dev_pred = model.predict(x_dev)\n","y_test_pred = model.predict(x_test)\n","\n","acc_train = accuracy_score(y_train, y_train_pred)\n","acc_dev = accuracy_score(y_dev, y_dev_pred)\n","acc_test = accuracy_score(y_test, y_test_pred)\n","f1_macro_test = f1_score(y_test, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[2]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["=================================================================================\n","Accuracy train:  0.9160500853727945\n","Accuracy dev:  0.40077821011673154\n","Accuracy test:  0.40299277605779155\n","F1 macro test:  0.4867361791597548\n","Recall macro test:  0.38873035140538775\n","Precision macro test:  0.7368795673553308\n","F1 micro test:  0.6382978723404256\n","Recall micro test:  0.5077976416888551\n","Precision micro test:  0.859073359073359\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"4CcyT56ukyRw"},"source":["# ========================================================"]},{"cell_type":"markdown","metadata":{"id":"6I6lurIjtDPZ"},"source":["# Model---Text-CNN---FastText"]},{"cell_type":"code","metadata":{"id":"lEUYmsjttJO7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624969277180,"user_tz":-420,"elapsed":161044,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"bdfdac1e-be08-4a1f-fcd5-143c13cc55c4"},"source":["x_train = X_train\n","x_dev = X_dev\n","x_test = X_test\n","\n","\n","def create_embedding_matrix(filepath, word_index, embedding_dim):\n","    vocab_size = len(word_index) + 1  \n","    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n","    with open(filepath) as f:\n","        for line in f:\n","            word, *vector = line.split()\n","            if word in word_index:\n","                idx = word_index[word] \n","                embedding_matrix[idx] = np.array(\n","                    vector, dtype = np.float32)[:embedding_dim]\n","    return embedding_matrix\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(x_train)\n","\n","maxlen = 50\n","vocab_size = len(tokenizer.word_index) + 1\n","embedding_dim = 300\n","word_vector = '/content/drive/MyDrive/NLP for Data Science/NLP_Project/Word_Embedding/cc.vi.300.vec'\n","embedding_matrix = create_embedding_matrix(word_vector, tokenizer.word_index, embedding_dim)\n","\n","x_train = tokenizer.texts_to_sequences(x_train)\n","x_dev = tokenizer.texts_to_sequences(x_dev)\n","x_test = tokenizer.texts_to_sequences(x_test)\n","\n","x_train = pad_sequences(x_train, maxlen = maxlen, truncating='post', padding='post')\n","x_dev = pad_sequences(x_dev, maxlen = maxlen, truncating='post', padding='post')\n","x_test = pad_sequences(x_test, maxlen = maxlen, truncating='post', padding='post')\n","\n","n_inputs, n_outputs = x_train.shape[1], y_train.shape[1]\n","\n","epochs = 10\n","batch_size = 256\n","\n","model = Sequential()\n","model.add(Embedding(input_dim = vocab_size, output_dim = embedding_dim, \n","                    weights = [embedding_matrix], input_length = maxlen, trainable = True))\n","model.add(Conv1D(128, 3, activation = 'relu'))\n","model.add(GlobalMaxPool1D())\n","model.add(Dense(128, activation = 'relu'))\n","model.add(Dense(n_outputs, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer = 'Adam', metrics= ['accuracy'])\n","# model.summary()\n","\n","model.fit(x_train, y_train, verbose=1, epochs=epochs, batch_size = batch_size, validation_data = (x_dev, y_dev))\n","\n","y_train_pred = model.predict(x_train).round() \n","y_dev_pred = model.predict(x_dev).round() \n","y_test_pred = model.predict(x_test).round() \n","\n","acc_train = accuracy_score(y_train, y_train_pred)\n","acc_dev = accuracy_score(y_dev, y_dev_pred)\n","acc_test = accuracy_score(y_test, y_test_pred)\n","f1_macro_test = f1_score(y_test, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[3]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",\n","          index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","28/28 [==============================] - 44s 54ms/step - loss: 0.5050 - accuracy: 0.1837 - val_loss: 0.3135 - val_accuracy: 0.2970\n","Epoch 2/10\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2952 - accuracy: 0.3531 - val_loss: 0.2610 - val_accuracy: 0.4319\n","Epoch 3/10\n","28/28 [==============================] - 1s 25ms/step - loss: 0.2378 - accuracy: 0.5389 - val_loss: 0.2107 - val_accuracy: 0.6096\n","Epoch 4/10\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1837 - accuracy: 0.6639 - val_loss: 0.1750 - val_accuracy: 0.6537\n","Epoch 5/10\n","28/28 [==============================] - 1s 27ms/step - loss: 0.1462 - accuracy: 0.7158 - val_loss: 0.1518 - val_accuracy: 0.6783\n","Epoch 6/10\n","28/28 [==============================] - 1s 28ms/step - loss: 0.1180 - accuracy: 0.7583 - val_loss: 0.1395 - val_accuracy: 0.6796\n","Epoch 7/10\n","28/28 [==============================] - 1s 27ms/step - loss: 0.0953 - accuracy: 0.7999 - val_loss: 0.1318 - val_accuracy: 0.6978\n","Epoch 8/10\n","28/28 [==============================] - 1s 28ms/step - loss: 0.0800 - accuracy: 0.8181 - val_loss: 0.1248 - val_accuracy: 0.7082\n","Epoch 9/10\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0633 - accuracy: 0.8356 - val_loss: 0.1222 - val_accuracy: 0.7095\n","Epoch 10/10\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0517 - accuracy: 0.8439 - val_loss: 0.1232 - val_accuracy: 0.7160\n","=================================================================================\n","Accuracy train:  0.8837507114399544\n","Accuracy dev:  0.5979247730220493\n","Accuracy test:  0.5877192982456141\n","F1 macro test:  0.7558124559236318\n","Recall macro test:  0.6996175595924811\n","Precision macro test:  0.8287123411349486\n","F1 micro test:  0.7818731117824774\n","Recall micro test:  0.7383035374667174\n","Precision micro test:  0.8309075342465754\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fl3oFi9bVDdq","executionInfo":{"status":"ok","timestamp":1624969277183,"user_tz":-420,"elapsed":61,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"28b7b17d-46c1-4f13-d3fb-dafa3a48866f"},"source":["acc_train = accuracy_score(y_train, y_train_pred)\n","acc_dev = accuracy_score(y_dev, y_dev_pred)\n","acc_test = accuracy_score(y_test, y_test_pred)\n","f1_macro_test = f1_score(y_test, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["=================================================================================\n","Accuracy train:  0.8837507114399544\n","Accuracy dev:  0.5979247730220493\n","Accuracy test:  0.5877192982456141\n","F1 macro test:  0.7558124559236318\n","Recall macro test:  0.6996175595924811\n","Precision macro test:  0.8287123411349486\n","F1 micro test:  0.7818731117824774\n","Recall micro test:  0.7383035374667174\n","Precision micro test:  0.8309075342465754\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uhnAklHDUV1p"},"source":["# Model---Text-CNN---Wikipedia Word2vec"]},{"cell_type":"code","metadata":{"id":"y6OKVLotUfo0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624969313495,"user_tz":-420,"elapsed":36369,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"f24da60f-555e-4985-80a1-a9a97996ca64"},"source":["x_train = X_train\n","x_dev = X_dev\n","x_test = X_test\n","\n","def __get_embedding_dict(model_filepath):\n","    embedding_dict = {}\n","    word2vec_model = KeyedVectors.load_word2vec_format(model_filepath, binary=True)\n","    vocab = [(word, word2vec_model.wv[word]) for word, vectors in word2vec_model.wv.vocab.items()]\n","\n","    for i in range(len(vocab)):\n","        word = vocab[i][0]\n","        vectors = vocab[i][1]\n","        embedding_dict[word] = vectors\n","\n","    return embedding_dict\n","\n","def create_embedding_matrix(model_filepath, word2id):\n","\n","    word2vec_model = KeyedVectors.load_word2vec_format(model_filepath, binary=True)\n","    embeddings_dict = __get_embedding_dict(model_filepath)\n","    embedding_matrix = np.zeros((len(word2id) + 1, word2vec_model.vector_size))\n","    for word, idx in word2id.items():\n","        embedding_vector = embeddings_dict.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[idx] = embedding_vector\n","\n","    return embedding_matrix \n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(x_train)\n","\n","maxlen = 50\n","embedding_dim = 400\n","vocab_size = len(tokenizer.word_index) + 1\n","model_filepath = '/content/drive/MyDrive/NLP for Data Science/NLP_Project/Word_Embedding/wiki.vi.model.bin'\n","embedding_matrix = create_embedding_matrix(model_filepath, tokenizer.word_index)\n","\n","x_train = tokenizer.texts_to_sequences(x_train)\n","x_dev = tokenizer.texts_to_sequences(x_dev)\n","x_test = tokenizer.texts_to_sequences(x_test)\n","\n","x_train = pad_sequences(x_train, maxlen = maxlen, truncating='post', padding='post')\n","x_dev = pad_sequences(x_dev, maxlen = maxlen, truncating='post', padding='post')\n","x_test = pad_sequences(x_test, maxlen = maxlen, truncating='post', padding='post')\n","\n","n_inputs, n_outputs = x_train.shape[1], y_train.shape[1]\n","\n","epochs = 10\n","batch_size = 256\n","\n","model = Sequential()\n","model.add(Embedding(input_dim = vocab_size, output_dim = embedding_dim, \n","                    weights = [embedding_matrix], input_length = maxlen, trainable = True))\n","model.add(Conv1D(128, 3, activation = 'relu'))\n","model.add(GlobalMaxPool1D())\n","model.add(Dense(128, activation = 'relu'))\n","model.add(Dense(n_outputs, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer = 'Adam', metrics= ['accuracy'])\n","# model.summary()\n","\n","model.fit(x_train, y_train, verbose=1, epochs=epochs, batch_size = batch_size, validation_data = (x_dev, y_dev))\n","\n","y_train_pred = model.predict(x_train).round() \n","y_dev_pred = model.predict(x_dev).round() \n","y_test_pred = model.predict(x_test).round() \n","\n","acc_train = accuracy_score(y_train, y_train_pred)\n","acc_dev = accuracy_score(y_dev, y_dev_pred)\n","acc_test = accuracy_score(y_test, y_test_pred)\n","f1_macro_test = f1_score(y_test, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[4]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",\n","          index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","28/28 [==============================] - 3s 63ms/step - loss: 0.5513 - accuracy: 0.2260 - val_loss: 0.2437 - val_accuracy: 0.4994\n","Epoch 2/10\n","28/28 [==============================] - 1s 40ms/step - loss: 0.2130 - accuracy: 0.5716 - val_loss: 0.1981 - val_accuracy: 0.5979\n","Epoch 3/10\n","28/28 [==============================] - 1s 40ms/step - loss: 0.1616 - accuracy: 0.6706 - val_loss: 0.1807 - val_accuracy: 0.6291\n","Epoch 4/10\n","28/28 [==============================] - 1s 43ms/step - loss: 0.1262 - accuracy: 0.7346 - val_loss: 0.1746 - val_accuracy: 0.6381\n","Epoch 5/10\n","28/28 [==============================] - 1s 43ms/step - loss: 0.1070 - accuracy: 0.7677 - val_loss: 0.1696 - val_accuracy: 0.6498\n","Epoch 6/10\n","28/28 [==============================] - 1s 45ms/step - loss: 0.0835 - accuracy: 0.7942 - val_loss: 0.1702 - val_accuracy: 0.6537\n","Epoch 7/10\n","28/28 [==============================] - 1s 44ms/step - loss: 0.0671 - accuracy: 0.8193 - val_loss: 0.1688 - val_accuracy: 0.6381\n","Epoch 8/10\n","28/28 [==============================] - 1s 44ms/step - loss: 0.0528 - accuracy: 0.8253 - val_loss: 0.1754 - val_accuracy: 0.6602\n","Epoch 9/10\n","28/28 [==============================] - 1s 45ms/step - loss: 0.0414 - accuracy: 0.8386 - val_loss: 0.1743 - val_accuracy: 0.6537\n","Epoch 10/10\n","28/28 [==============================] - 1s 45ms/step - loss: 0.0311 - accuracy: 0.8509 - val_loss: 0.1829 - val_accuracy: 0.6342\n","=================================================================================\n","Accuracy train:  0.9678429140580534\n","Accuracy dev:  0.4708171206225681\n","Accuracy test:  0.5036119711042312\n","F1 macro test:  0.649569328174602\n","Recall macro test:  0.578360175611769\n","Precision macro test:  0.7563461869852515\n","F1 micro test:  0.7232255354892902\n","Recall micro test:  0.6550019018638266\n","Precision micro test:  0.8073136427566807\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bNXkEYgyUih6"},"source":["# Model---Text-CNN---BPEmb"]},{"cell_type":"code","metadata":{"id":"Z6gNeW0RUrfC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624969357521,"user_tz":-420,"elapsed":44064,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"7a02b231-f116-41e6-9e65-a6c31e4cfe33"},"source":["!pip install bpemb\n","\n","x_train = X_train\n","x_dev = X_dev\n","x_test = X_test\n","\n","from bpemb import BPEmb\n","bpemb_vi = BPEmb(lang = 'vi', dim = 300, vs = 200000)\n","\n","def __get_embedding_dict(model_filepath):\n","    embedding_dict = {}\n","    word2vec_model = KeyedVectors.load_word2vec_format(model_filepath, binary=True)\n","    vocab = [(word, word2vec_model.wv[word]) for word, vectors in word2vec_model.wv.vocab.items()]\n","    for i in range(len(vocab)):\n","        word = vocab[i][0]\n","        vectors = vocab[i][1]\n","        embedding_dict[word] = vectors\n","    return embedding_dict\n","\n","def create_embedding_matrix(model_filepath, word2id):\n","    word2vec_model = KeyedVectors.load_word2vec_format(model_filepath, binary=True)\n","    embeddings_dict = __get_embedding_dict(model_filepath)\n","    embedding_matrix = np.zeros((len(word2id) + 1, word2vec_model.vector_size))\n","    for word, idx in word2id.items():\n","        embedding_vector = embeddings_dict.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[idx] = embedding_vector\n","    return embedding_matrix \n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(x_train)\n","\n","maxlen = 50\n","embedding_dim = 300\n","vocab_size = len(tokenizer.word_index) + 1\n","model_filepath = bpemb_vi.emb_file\n","embedding_matrix = create_embedding_matrix(model_filepath, tokenizer.word_index)\n","\n","x_train = tokenizer.texts_to_sequences(x_train)\n","x_dev = tokenizer.texts_to_sequences(x_dev)\n","x_test = tokenizer.texts_to_sequences(x_test)\n","\n","x_train = pad_sequences(x_train, maxlen = maxlen, truncating='post', padding='post')\n","x_dev = pad_sequences(x_dev, maxlen = maxlen, truncating='post', padding='post')\n","x_test = pad_sequences(x_test, maxlen = maxlen, truncating='post', padding='post')\n","\n","n_inputs, n_outputs = x_train.shape[1], y_train.shape[1]\n","\n","epochs = 10\n","batch_size = 256\n","\n","model = Sequential()\n","model.add(Embedding(input_dim = vocab_size, output_dim = embedding_dim, \n","                    weights = [embedding_matrix], input_length = maxlen, trainable = True))\n","model.add(Conv1D(128, 3, activation = 'relu'))\n","model.add(GlobalMaxPool1D())\n","model.add(Dense(128, activation = 'relu'))\n","model.add(Dense(n_outputs, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer = 'Adam', metrics= ['accuracy'])\n","# model.summary()\n","\n","model.fit(x_train, y_train, verbose=1, epochs=epochs, batch_size = batch_size, validation_data = (x_dev, y_dev))\n","\n","y_train_pred = model.predict(x_train).round() \n","y_dev_pred = model.predict(x_dev).round() \n","y_test_pred = model.predict(x_test).round() \n","\n","acc_train = accuracy_score(y_train, y_train_pred)\n","acc_dev = accuracy_score(y_dev, y_dev_pred)\n","acc_test = accuracy_score(y_test, y_test_pred)\n","f1_macro_test = f1_score(y_test, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[5]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",\n","          index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting bpemb\n","  Downloading https://files.pythonhosted.org/packages/f2/6f/9191b85109772636a8f8accb122900c34db26c091d2793218aa94954524c/bpemb-0.3.3-py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb) (1.19.5)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from bpemb) (3.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bpemb) (2.23.0)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 8.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bpemb) (4.41.1)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.4.1)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.15.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (5.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (1.24.3)\n","Installing collected packages: sentencepiece, bpemb\n","Successfully installed bpemb-0.3.3 sentencepiece-0.1.96\n","downloading https://nlp.h-its.org/bpemb/vi/vi.wiki.bpe.vs200000.model\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 3659179/3659179 [00:01<00:00, 3543833.63B/s]\n"],"name":"stderr"},{"output_type":"stream","text":["downloading https://nlp.h-its.org/bpemb/vi/vi.wiki.bpe.vs200000.d300.w2v.bin.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 223674818/223674818 [00:13<00:00, 16225494.48B/s]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  del sys.path[0]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","28/28 [==============================] - 2s 40ms/step - loss: 0.4402 - accuracy: 0.2433 - val_loss: 0.2793 - val_accuracy: 0.4540\n","Epoch 2/10\n","28/28 [==============================] - 1s 31ms/step - loss: 0.2492 - accuracy: 0.5177 - val_loss: 0.2185 - val_accuracy: 0.5642\n","Epoch 3/10\n","28/28 [==============================] - 1s 30ms/step - loss: 0.1879 - accuracy: 0.6418 - val_loss: 0.1843 - val_accuracy: 0.6031\n","Epoch 4/10\n","28/28 [==============================] - 1s 31ms/step - loss: 0.1519 - accuracy: 0.6823 - val_loss: 0.1675 - val_accuracy: 0.6342\n","Epoch 5/10\n","28/28 [==============================] - 1s 30ms/step - loss: 0.1271 - accuracy: 0.7290 - val_loss: 0.1555 - val_accuracy: 0.6394\n","Epoch 6/10\n","28/28 [==============================] - 1s 32ms/step - loss: 0.1061 - accuracy: 0.7575 - val_loss: 0.1479 - val_accuracy: 0.6537\n","Epoch 7/10\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0858 - accuracy: 0.7982 - val_loss: 0.1449 - val_accuracy: 0.6667\n","Epoch 8/10\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0713 - accuracy: 0.8086 - val_loss: 0.1430 - val_accuracy: 0.6732\n","Epoch 9/10\n","28/28 [==============================] - 1s 30ms/step - loss: 0.0582 - accuracy: 0.8151 - val_loss: 0.1462 - val_accuracy: 0.6783\n","Epoch 10/10\n","28/28 [==============================] - 1s 31ms/step - loss: 0.0456 - accuracy: 0.8335 - val_loss: 0.1458 - val_accuracy: 0.6900\n","=================================================================================\n","Accuracy train:  0.9176152532726238\n","Accuracy dev:  0.5278858625162127\n","Accuracy test:  0.544891640866873\n","F1 macro test:  0.698524517013103\n","Recall macro test:  0.629393658765414\n","Precision macro test:  0.8090902188738868\n","F1 micro test:  0.7513903192584964\n","Recall micro test:  0.693799923925447\n","Precision micro test:  0.8194070080862533\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O8EeDz9oUyeg"},"source":["# Model---Text-CNN---MULTI_WC_F_E_B"]},{"cell_type":"code","metadata":{"id":"GcSZ_cNwUy9P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624969384214,"user_tz":-420,"elapsed":26726,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"8200c154-1d95-4a7c-87e4-45b4345da95a"},"source":["x_train = X_train\n","x_dev = X_dev\n","x_test = X_test\n","\n","# Embedding matrix\n","def create_embedding_matrix(filepath, word_index, embedding_dim):\n","    vocab_size = len(word_index) + 1  \n","    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n","\n","    with open(filepath) as f:\n","        for line in f:\n","            word, *vector = line.split()\n","            if word in word_index:\n","                idx = word_index[word] \n","                embedding_matrix[idx] = np.array(\n","                    vector, dtype = np.float32)[:embedding_dim]\n","    return embedding_matrix\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(x_train)\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","maxlen = 50\n","embedding_dim = 300\n","word_vector = '/content/drive/MyDrive/NLP for Data Science/NLP_Project/Word_Embedding/MULTI_W_F_B_E.vec'\n","embedding_matrix = create_embedding_matrix(word_vector, tokenizer.word_index, embedding_dim)\n","\n","x_train = tokenizer.texts_to_sequences(x_train)\n","x_dev = tokenizer.texts_to_sequences(x_dev)\n","x_test = tokenizer.texts_to_sequences(x_test)\n","\n","x_train = pad_sequences(x_train, maxlen = maxlen, truncating='post', padding='post')\n","x_dev = pad_sequences(x_dev, maxlen = maxlen, truncating='post', padding='post')\n","x_test = pad_sequences(x_test, maxlen = maxlen, truncating='post', padding='post')\n","\n","n_inputs, n_outputs = x_train.shape[1], y_train.shape[1]\n","\n","epochs = 10\n","batch_size = 256\n","\n","model = Sequential()\n","model.add(Embedding(input_dim = vocab_size, output_dim = embedding_dim, \n","                    weights = [embedding_matrix], input_length = maxlen, trainable = True))\n","model.add(Conv1D(128, 3, activation = 'relu'))\n","model.add(GlobalMaxPool1D())\n","model.add(Dense(128, activation = 'relu'))\n","model.add(Dense(n_outputs, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer = 'Adam', metrics= ['accuracy'])\n","# model.summary()\n","\n","model.fit(x_train, y_train, verbose=1, epochs=epochs, batch_size = batch_size, validation_data = (x_dev, y_dev))\n","\n","y_train_pred = model.predict(x_train).round() \n","y_dev_pred = model.predict(x_dev).round() \n","y_test_pred = model.predict(x_test).round() \n","\n","acc_train = accuracy_score(y_train, y_train_pred)\n","acc_dev = accuracy_score(y_dev, y_dev_pred)\n","acc_test = accuracy_score(y_test, y_test_pred)\n","f1_macro_test = f1_score(y_test, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[6]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",\n","          index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","28/28 [==============================] - 2s 41ms/step - loss: 0.5463 - accuracy: 0.1937 - val_loss: 0.3309 - val_accuracy: 0.2594\n","Epoch 2/10\n","28/28 [==============================] - 1s 32ms/step - loss: 0.3143 - accuracy: 0.3091 - val_loss: 0.2752 - val_accuracy: 0.4008\n","Epoch 3/10\n","28/28 [==============================] - 1s 31ms/step - loss: 0.2548 - accuracy: 0.4801 - val_loss: 0.2277 - val_accuracy: 0.5344\n","Epoch 4/10\n","28/28 [==============================] - 1s 32ms/step - loss: 0.2045 - accuracy: 0.5903 - val_loss: 0.1935 - val_accuracy: 0.6005\n","Epoch 5/10\n","28/28 [==============================] - 1s 31ms/step - loss: 0.1633 - accuracy: 0.6688 - val_loss: 0.1648 - val_accuracy: 0.6304\n","Epoch 6/10\n","28/28 [==============================] - 1s 32ms/step - loss: 0.1348 - accuracy: 0.7145 - val_loss: 0.1473 - val_accuracy: 0.6602\n","Epoch 7/10\n","28/28 [==============================] - 1s 34ms/step - loss: 0.1083 - accuracy: 0.7609 - val_loss: 0.1372 - val_accuracy: 0.6796\n","Epoch 8/10\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0897 - accuracy: 0.7843 - val_loss: 0.1307 - val_accuracy: 0.6757\n","Epoch 9/10\n","28/28 [==============================] - 1s 34ms/step - loss: 0.0710 - accuracy: 0.8136 - val_loss: 0.1281 - val_accuracy: 0.6835\n","Epoch 10/10\n","28/28 [==============================] - 1s 32ms/step - loss: 0.0564 - accuracy: 0.8317 - val_loss: 0.1279 - val_accuracy: 0.6965\n","=================================================================================\n","Accuracy train:  0.8599886169607285\n","Accuracy dev:  0.5732814526588845\n","Accuracy test:  0.5902992776057792\n","F1 macro test:  0.73776706334288\n","Recall macro test:  0.6679946346088578\n","Precision macro test:  0.8362929509903788\n","F1 micro test:  0.7815333882934873\n","Recall micro test:  0.7211867630277672\n","Precision micro test:  0.8529014844804319\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KbI_9hZDk4Zl"},"source":["# ============================================="]},{"cell_type":"markdown","metadata":{"id":"6-n2O6qvt6H7"},"source":["# Model---Bi-GRU---FastText"]},{"cell_type":"code","metadata":{"id":"a1TAu5bEVG9h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624969540012,"user_tz":-420,"elapsed":155824,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"1754ea97-8607-4744-a12e-904c34ac3a06"},"source":["x_train = X_train\n","x_dev = X_dev\n","x_test = X_test\n","\n","# Embedding matrix\n","def create_embedding_matrix(filepath, word_index, embedding_dim):\n","    vocab_size = len(word_index) + 1  \n","    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n","\n","    with open(filepath) as f:\n","        for line in f:\n","            word, *vector = line.split()\n","            if word in word_index:\n","                idx = word_index[word] \n","                embedding_matrix[idx] = np.array(\n","                    vector, dtype = np.float32)[:embedding_dim]\n","    return embedding_matrix\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(x_train)\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","maxlen = 50\n","embedding_dim = 300\n","word_vector = '/content/drive/MyDrive/NLP for Data Science/NLP_Project/Word_Embedding/cc.vi.300.vec'\n","embedding_matrix = create_embedding_matrix(word_vector, tokenizer.word_index, embedding_dim)\n","\n","x_train = tokenizer.texts_to_sequences(x_train)\n","x_dev = tokenizer.texts_to_sequences(x_dev)\n","x_test = tokenizer.texts_to_sequences(x_test)\n","\n","x_train = pad_sequences(x_train, maxlen = maxlen, truncating='post', padding='post')\n","x_dev = pad_sequences(x_dev, maxlen = maxlen, truncating='post', padding='post')\n","x_test = pad_sequences(x_test, maxlen = maxlen, truncating='post', padding='post')\n","\n","n_inputs, n_outputs = x_train.shape[1], y_train.shape[1]\n","\n","epochs = 10\n","batch_size = 256\n","\n","model = Sequential()\n","model.add(Embedding(input_dim = vocab_size, output_dim = embedding_dim, \n","                    weights = [embedding_matrix], input_length = maxlen, trainable = True))\n","model.add(Bidirectional(GRU(50, return_sequences=True)))\n","model.add(GlobalMaxPool1D())\n","model.add(Dropout(0.1))\n","model.add(Dense(50, activation=\"relu\"))\n","model.add(Dropout(0.1))\n","model.add(Dense(128, activation = 'relu'))\n","model.add(Dense(n_outputs, activation = 'sigmoid'))\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","# model.summary()\n","\n","model.fit(x_train, y_train, verbose=1, epochs=epochs, batch_size = batch_size, validation_data = (x_dev, y_dev))\n","\n","y_train_pred = model.predict(x_train).round() \n","y_dev_pred = model.predict(x_dev).round() \n","y_test_pred = model.predict(x_test).round() \n","\n","acc_train = accuracy_score(y_train, y_train_pred)\n","acc_dev = accuracy_score(y_dev, y_dev_pred)\n","acc_test = accuracy_score(y_test, y_test_pred)\n","f1_macro_test = f1_score(y_test, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[7]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",\n","          index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","28/28 [==============================] - 11s 67ms/step - loss: 0.5765 - accuracy: 0.0746 - val_loss: 0.3384 - val_accuracy: 0.2503\n","Epoch 2/10\n","28/28 [==============================] - 1s 36ms/step - loss: 0.3287 - accuracy: 0.2531 - val_loss: 0.3084 - val_accuracy: 0.2853\n","Epoch 3/10\n","28/28 [==============================] - 1s 38ms/step - loss: 0.2922 - accuracy: 0.3390 - val_loss: 0.2558 - val_accuracy: 0.4708\n","Epoch 4/10\n","28/28 [==============================] - 1s 36ms/step - loss: 0.2414 - accuracy: 0.4920 - val_loss: 0.2140 - val_accuracy: 0.5318\n","Epoch 5/10\n","28/28 [==============================] - 1s 36ms/step - loss: 0.1987 - accuracy: 0.5658 - val_loss: 0.1832 - val_accuracy: 0.6018\n","Epoch 6/10\n","28/28 [==============================] - 1s 35ms/step - loss: 0.1614 - accuracy: 0.6494 - val_loss: 0.1608 - val_accuracy: 0.6576\n","Epoch 7/10\n","28/28 [==============================] - 1s 35ms/step - loss: 0.1304 - accuracy: 0.7206 - val_loss: 0.1475 - val_accuracy: 0.6822\n","Epoch 8/10\n","28/28 [==============================] - 1s 36ms/step - loss: 0.1120 - accuracy: 0.7630 - val_loss: 0.1427 - val_accuracy: 0.7043\n","Epoch 9/10\n","28/28 [==============================] - 1s 36ms/step - loss: 0.0956 - accuracy: 0.7989 - val_loss: 0.1381 - val_accuracy: 0.7108\n","Epoch 10/10\n","28/28 [==============================] - 1s 35ms/step - loss: 0.0833 - accuracy: 0.8191 - val_loss: 0.1364 - val_accuracy: 0.7173\n","=================================================================================\n","Accuracy train:  0.7951052931132613\n","Accuracy dev:  0.5875486381322957\n","Accuracy test:  0.6222910216718266\n","F1 macro test:  0.7550632977782361\n","Recall macro test:  0.7008004785383727\n","Precision macro test:  0.8260508704307439\n","F1 micro test:  0.7864625302175665\n","Recall micro test:  0.7424876378851274\n","Precision micro test:  0.8359743040685225\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WWI33_wiKB9R"},"source":["# Model---Bi-GRU---Wikipedia Word2vec"]},{"cell_type":"code","metadata":{"id":"Uy2kJ6igKCO6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624969567160,"user_tz":-420,"elapsed":27187,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"6358fb2f-80d1-4551-86c2-6775ff5d470a"},"source":["x_train = X_train\n","x_dev = X_dev\n","x_test = X_test\n","\n","def __get_embedding_dict(model_filepath):\n","    embedding_dict = {}\n","    word2vec_model = KeyedVectors.load_word2vec_format(model_filepath, binary=True)\n","    vocab = [(word, word2vec_model.wv[word]) for word, vectors in word2vec_model.wv.vocab.items()]\n","\n","    for i in range(len(vocab)):\n","        word = vocab[i][0]\n","        vectors = vocab[i][1]\n","        embedding_dict[word] = vectors\n","\n","    return embedding_dict\n","\n","def create_embedding_matrix(model_filepath, word2id):\n","    word2vec_model = KeyedVectors.load_word2vec_format(model_filepath, binary=True)\n","    embeddings_dict = __get_embedding_dict(model_filepath)\n","    embedding_matrix = np.zeros((len(word2id) + 1, word2vec_model.vector_size))\n","    for word, idx in word2id.items():\n","        embedding_vector = embeddings_dict.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[idx] = embedding_vector\n","\n","    return embedding_matrix \n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(x_train)\n","\n","maxlen = 50\n","embedding_dim = 400\n","vocab_size = len(tokenizer.word_index) + 1\n","model_filepath = '/content/drive/MyDrive/NLP for Data Science/NLP_Project/Word_Embedding/wiki.vi.model.bin'\n","embedding_matrix = create_embedding_matrix(model_filepath, tokenizer.word_index)\n","\n","x_train = tokenizer.texts_to_sequences(x_train)\n","x_dev = tokenizer.texts_to_sequences(x_dev)\n","x_test = tokenizer.texts_to_sequences(x_test)\n","\n","x_train = pad_sequences(x_train, maxlen = maxlen, truncating='post', padding='post')\n","x_dev = pad_sequences(x_dev, maxlen = maxlen, truncating='post', padding='post')\n","x_test = pad_sequences(x_test, maxlen = maxlen, truncating='post', padding='post')\n","\n","n_inputs, n_outputs = x_train.shape[1], y_train.shape[1]\n","\n","epochs = 10\n","batch_size = 256\n","\n","model = Sequential()\n","model.add(Embedding(input_dim = vocab_size, output_dim = embedding_dim, \n","                    weights = [embedding_matrix], input_length = maxlen, trainable = True))\n","model.add(Bidirectional(GRU(50, return_sequences=True)))\n","model.add(GlobalMaxPool1D())\n","model.add(Dropout(0.1))\n","model.add(Dense(50, activation=\"relu\"))\n","model.add(Dropout(0.1))\n","model.add(Dense(128, activation = 'relu'))\n","model.add(Dense(n_outputs, activation = 'sigmoid'))\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","# model.summary()\n","\n","model.fit(x_train, y_train, verbose=1, epochs=epochs, batch_size = batch_size, validation_data = (x_dev, y_dev))\n","\n","y_train_pred = model.predict(x_train).round() \n","y_dev_pred = model.predict(x_dev).round() \n","y_test_pred = model.predict(x_test).round() \n","\n","acc_train = accuracy_score(y_train, y_train_pred)\n","acc_dev = accuracy_score(y_dev, y_dev_pred)\n","acc_test = accuracy_score(y_test, y_test_pred)\n","f1_macro_test = f1_score(y_test, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[8]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",\n","          index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","28/28 [==============================] - 5s 73ms/step - loss: 0.5792 - accuracy: 0.1429 - val_loss: 0.3254 - val_accuracy: 0.2594\n","Epoch 2/10\n","28/28 [==============================] - 1s 44ms/step - loss: 0.3151 - accuracy: 0.2724 - val_loss: 0.2775 - val_accuracy: 0.4112\n","Epoch 3/10\n","28/28 [==============================] - 1s 44ms/step - loss: 0.2694 - accuracy: 0.4029 - val_loss: 0.2341 - val_accuracy: 0.5032\n","Epoch 4/10\n","28/28 [==============================] - 1s 45ms/step - loss: 0.2258 - accuracy: 0.5242 - val_loss: 0.1998 - val_accuracy: 0.5629\n","Epoch 5/10\n","28/28 [==============================] - 1s 46ms/step - loss: 0.1930 - accuracy: 0.5910 - val_loss: 0.1798 - val_accuracy: 0.6083\n","Epoch 6/10\n","28/28 [==============================] - 1s 48ms/step - loss: 0.1703 - accuracy: 0.6490 - val_loss: 0.1639 - val_accuracy: 0.6226\n","Epoch 7/10\n","28/28 [==============================] - 1s 48ms/step - loss: 0.1531 - accuracy: 0.6614 - val_loss: 0.1541 - val_accuracy: 0.6252\n","Epoch 8/10\n","28/28 [==============================] - 1s 47ms/step - loss: 0.1376 - accuracy: 0.6977 - val_loss: 0.1484 - val_accuracy: 0.6355\n","Epoch 9/10\n","28/28 [==============================] - 1s 48ms/step - loss: 0.1227 - accuracy: 0.7235 - val_loss: 0.1439 - val_accuracy: 0.6732\n","Epoch 10/10\n","28/28 [==============================] - 1s 49ms/step - loss: 0.1159 - accuracy: 0.7386 - val_loss: 0.1406 - val_accuracy: 0.6770\n","=================================================================================\n","Accuracy train:  0.6950768355150825\n","Accuracy dev:  0.5356679636835279\n","Accuracy test:  0.5603715170278638\n","F1 macro test:  0.66105313028404\n","Recall macro test:  0.5959477960172767\n","Precision macro test:  0.8030696129440895\n","F1 micro test:  0.7523770152955767\n","Recall micro test:  0.6922784328642069\n","Precision micro test:  0.8239022181982798\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DU5w1OPUVU9u"},"source":["# Model---Bi-GRU---BPEmb"]},{"cell_type":"code","metadata":{"id":"bgKa1QlWOVDB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624969604511,"user_tz":-420,"elapsed":37388,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"d8ccf887-c905-457b-b94f-94cea7e28022"},"source":["!pip install bpemb\n","\n","x_train = X_train\n","x_dev = X_dev\n","x_test = X_test\n","\n","from bpemb import BPEmb\n","bpemb_vi = BPEmb(lang = 'vi', dim = 300, vs = 200000)\n","\n","def __get_embedding_dict(model_filepath):\n","    embedding_dict = {}\n","    word2vec_model = KeyedVectors.load_word2vec_format(model_filepath, binary=True)\n","    vocab = [(word, word2vec_model.wv[word]) for word, vectors in word2vec_model.wv.vocab.items()]\n","\n","    for i in range(len(vocab)):\n","        word = vocab[i][0]\n","        vectors = vocab[i][1]\n","        embedding_dict[word] = vectors\n","\n","    return embedding_dict\n","\n","def create_embedding_matrix(model_filepath, word2id):\n","    \"\"\"\n","    Get the embedding matrix of the word2vec model\n","    :param model_filepath: the file path to the pre-build word2vec model\n","    :param word2id: the directory mapping from word to id\n","    :return: the embedding matrix of the word2vec model\n","    \"\"\"\n","    word2vec_model = KeyedVectors.load_word2vec_format(model_filepath, binary=True)\n","    embeddings_dict = __get_embedding_dict(model_filepath)\n","    embedding_matrix = np.zeros((len(word2id) + 1, word2vec_model.vector_size))\n","    for word, idx in word2id.items():\n","        embedding_vector = embeddings_dict.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[idx] = embedding_vector\n","\n","    return embedding_matrix \n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(x_train)\n","\n","maxlen = 50\n","embedding_dim = 300\n","vocab_size = len(tokenizer.word_index) + 1\n","model_filepath = bpemb_vi.emb_file\n","embedding_matrix = create_embedding_matrix(model_filepath, tokenizer.word_index)\n","\n","x_train = tokenizer.texts_to_sequences(x_train)\n","x_dev = tokenizer.texts_to_sequences(x_dev)\n","x_test = tokenizer.texts_to_sequences(x_test)\n","\n","x_train = pad_sequences(x_train, maxlen = maxlen, truncating='post', padding='post')\n","x_dev = pad_sequences(x_dev, maxlen = maxlen, truncating='post', padding='post')\n","x_test = pad_sequences(x_test, maxlen = maxlen, truncating='post', padding='post')\n","\n","n_inputs, n_outputs = x_train.shape[1], y_train.shape[1]\n","\n","epochs = 10\n","batch_size = 256\n","\n","model = Sequential()\n","model.add(Embedding(input_dim = vocab_size, output_dim = embedding_dim, \n","                    weights = [embedding_matrix], input_length = maxlen, trainable = True))\n","model.add(Bidirectional(GRU(50, return_sequences=True)))\n","model.add(GlobalMaxPool1D())\n","model.add(Dropout(0.1))\n","model.add(Dense(50, activation=\"relu\"))\n","model.add(Dropout(0.1))\n","model.add(Dense(128, activation = 'relu'))\n","model.add(Dense(n_outputs, activation = 'sigmoid'))\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","# model.summary()\n","\n","model.fit(x_train, y_train, verbose=1, epochs=epochs, batch_size = batch_size, validation_data = (x_dev, y_dev))\n","\n","y_train_pred = model.predict(x_train).round() \n","y_dev_pred = model.predict(x_dev).round() \n","y_test_pred = model.predict(x_test).round() \n","\n","acc_train = accuracy_score(y_train, y_train_pred)\n","acc_dev = accuracy_score(y_dev, y_dev_pred)\n","acc_test = accuracy_score(y_test, y_test_pred)\n","f1_macro_test = f1_score(y_test, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[9]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",\n","          index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: bpemb in /usr/local/lib/python3.7/dist-packages (0.3.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bpemb) (4.41.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from bpemb) (0.1.96)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bpemb) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb) (1.19.5)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from bpemb) (3.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (3.0.4)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.4.1)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.15.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (5.1.0)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  del sys.path[0]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","28/28 [==============================] - 5s 67ms/step - loss: 0.5477 - accuracy: 0.1094 - val_loss: 0.3348 - val_accuracy: 0.2503\n","Epoch 2/10\n","28/28 [==============================] - 1s 34ms/step - loss: 0.3272 - accuracy: 0.2509 - val_loss: 0.2995 - val_accuracy: 0.3424\n","Epoch 3/10\n","28/28 [==============================] - 1s 35ms/step - loss: 0.2852 - accuracy: 0.3929 - val_loss: 0.2390 - val_accuracy: 0.4929\n","Epoch 4/10\n","28/28 [==============================] - 1s 34ms/step - loss: 0.2293 - accuracy: 0.5191 - val_loss: 0.1990 - val_accuracy: 0.5577\n","Epoch 5/10\n","28/28 [==============================] - 1s 34ms/step - loss: 0.1855 - accuracy: 0.6015 - val_loss: 0.1751 - val_accuracy: 0.5992\n","Epoch 6/10\n","28/28 [==============================] - 1s 34ms/step - loss: 0.1579 - accuracy: 0.6391 - val_loss: 0.1574 - val_accuracy: 0.6226\n","Epoch 7/10\n","28/28 [==============================] - 1s 34ms/step - loss: 0.1353 - accuracy: 0.6940 - val_loss: 0.1470 - val_accuracy: 0.6550\n","Epoch 8/10\n","28/28 [==============================] - 1s 34ms/step - loss: 0.1172 - accuracy: 0.7379 - val_loss: 0.1415 - val_accuracy: 0.6602\n","Epoch 9/10\n","28/28 [==============================] - 1s 33ms/step - loss: 0.1041 - accuracy: 0.7627 - val_loss: 0.1367 - val_accuracy: 0.6732\n","Epoch 10/10\n","28/28 [==============================] - 1s 36ms/step - loss: 0.0899 - accuracy: 0.7860 - val_loss: 0.1349 - val_accuracy: 0.6874\n","=================================================================================\n","Accuracy train:  0.776038702333523\n","Accuracy dev:  0.5538261997405967\n","Accuracy test:  0.5923632610939112\n","F1 macro test:  0.7309901059525501\n","Recall macro test:  0.6714184266468979\n","Precision macro test:  0.8186950543435284\n","F1 micro test:  0.7771313941825476\n","Recall micro test:  0.7367820464054774\n","Precision micro test:  0.8221561969439728\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wpXpcrP0VeBl"},"source":["# Model---Bi-GRU---MULTI_WC_F_E_B"]},{"cell_type":"code","metadata":{"id":"q0DSWWIrVjpS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624969639336,"user_tz":-420,"elapsed":34861,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"f0ba494d-25e3-48d5-c2b5-98b019e6fc1b"},"source":["x_train = X_train\n","x_dev = X_dev\n","x_test = X_test\n","\n","# Embedding matrix\n","def create_embedding_matrix(filepath, word_index, embedding_dim):\n","    vocab_size = len(word_index) + 1  \n","    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n","\n","    with open(filepath) as f:\n","        for line in f:\n","            word, *vector = line.split()\n","            if word in word_index:\n","                idx = word_index[word] \n","                embedding_matrix[idx] = np.array(\n","                    vector, dtype = np.float32)[:embedding_dim]\n","    return embedding_matrix\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(x_train)\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","maxlen = 50\n","embedding_dim = 300\n","word_vector = '/content/drive/MyDrive/NLP for Data Science/NLP_Project/Word_Embedding/MULTI_W_F_B_E.vec'\n","embedding_matrix = create_embedding_matrix(word_vector, tokenizer.word_index, embedding_dim)\n","\n","x_train = tokenizer.texts_to_sequences(x_train)\n","x_dev = tokenizer.texts_to_sequences(x_dev)\n","x_test = tokenizer.texts_to_sequences(x_test)\n","\n","x_train = pad_sequences(x_train, maxlen = maxlen, truncating='post', padding='post')\n","x_dev = pad_sequences(x_dev, maxlen = maxlen, truncating='post', padding='post')\n","x_test = pad_sequences(x_test, maxlen = maxlen, truncating='post', padding='post')\n","\n","n_inputs, n_outputs = x_train.shape[1], y_train.shape[1]\n","\n","epochs = 10\n","batch_size = 256\n","\n","model = Sequential()\n","model.add(Embedding(input_dim = vocab_size, output_dim = embedding_dim, \n","                    weights = [embedding_matrix], input_length = maxlen, trainable = True))\n","model.add(Bidirectional(GRU(50, return_sequences=True)))\n","model.add(GlobalMaxPool1D())\n","model.add(Dropout(0.1))\n","model.add(Dense(50, activation=\"relu\"))\n","model.add(Dropout(0.1))\n","model.add(Dense(128, activation = 'relu'))\n","model.add(Dense(n_outputs, activation = 'sigmoid'))\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","# model.summary()\n","\n","model.fit(x_train, y_train, verbose=1, epochs=epochs, batch_size = batch_size, validation_data = (x_dev, y_dev))\n","\n","y_train_pred = model.predict(x_train).round() \n","y_dev_pred = model.predict(x_dev).round() \n","y_test_pred = model.predict(x_test).round() \n","\n","acc_train = accuracy_score(y_train, y_train_pred)\n","acc_dev = accuracy_score(y_dev, y_dev_pred)\n","acc_test = accuracy_score(y_test, y_test_pred)\n","f1_macro_test = f1_score(y_test, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[10]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",\n","          index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","28/28 [==============================] - 5s 65ms/step - loss: 0.6116 - accuracy: 0.0801 - val_loss: 0.3524 - val_accuracy: 0.2503\n","Epoch 2/10\n","28/28 [==============================] - 1s 36ms/step - loss: 0.3373 - accuracy: 0.2437 - val_loss: 0.3260 - val_accuracy: 0.2503\n","Epoch 3/10\n","28/28 [==============================] - 1s 37ms/step - loss: 0.3185 - accuracy: 0.2542 - val_loss: 0.2989 - val_accuracy: 0.3100\n","Epoch 4/10\n","28/28 [==============================] - 1s 36ms/step - loss: 0.2831 - accuracy: 0.3443 - val_loss: 0.2451 - val_accuracy: 0.4669\n","Epoch 5/10\n","28/28 [==============================] - 1s 36ms/step - loss: 0.2271 - accuracy: 0.5059 - val_loss: 0.1959 - val_accuracy: 0.5707\n","Epoch 6/10\n","28/28 [==============================] - 1s 36ms/step - loss: 0.1734 - accuracy: 0.6182 - val_loss: 0.1649 - val_accuracy: 0.6226\n","Epoch 7/10\n","28/28 [==============================] - 1s 37ms/step - loss: 0.1428 - accuracy: 0.6865 - val_loss: 0.1451 - val_accuracy: 0.6693\n","Epoch 8/10\n","28/28 [==============================] - 1s 37ms/step - loss: 0.1132 - accuracy: 0.7354 - val_loss: 0.1372 - val_accuracy: 0.6835\n","Epoch 9/10\n","28/28 [==============================] - 1s 37ms/step - loss: 0.0932 - accuracy: 0.7616 - val_loss: 0.1353 - val_accuracy: 0.6952\n","Epoch 10/10\n","28/28 [==============================] - 1s 37ms/step - loss: 0.0822 - accuracy: 0.7921 - val_loss: 0.1367 - val_accuracy: 0.7043\n","=================================================================================\n","Accuracy train:  0.8074843483210017\n","Accuracy dev:  0.5888456549935149\n","Accuracy test:  0.6052631578947368\n","F1 macro test:  0.7470834003421759\n","Recall macro test:  0.697663088447995\n","Precision macro test:  0.8139601541422801\n","F1 micro test:  0.7823318742538797\n","Recall micro test:  0.7478128565994675\n","Precision micro test:  0.820191906549854\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XQCXgytVp-OX"},"source":["# ========================================================="]},{"cell_type":"code","metadata":{"id":"sty0dCZ497Oc"},"source":["max_len = max([len(text.split(\" \")) for text in X_train])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vqHSmChDNRy6"},"source":["# BERT XLM-R"]},{"cell_type":"code","metadata":{"id":"KryMKxjgNSQq","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1624975308639,"user_tz":-420,"elapsed":1504152,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"ea332467-7f90-459d-d945-77664944de0b"},"source":["class BuildDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, tokenizer, X, y, max_len):\n","        self.tokenizer = tokenizer\n","        self.comment_text = X\n","        self.targets = y\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.comment_text)\n","\n","    def __getitem__(self, index):\n","        comment_text = str(self.comment_text[index])\n","        comment_text = \" \".join(comment_text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            comment_text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","\n","        return {\n","            'input_ids': torch.tensor(ids, dtype=torch.long),\n","            'attention_mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'labels': torch.tensor(self.targets[index], dtype=torch.float)\n","        }\n","\n","# Khai bao pre-trained\n","model = AutoModelForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels = 12)\n","tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n","\n","# Chuan bi data\n","train_dataset = BuildDataset(tokenizer, X_train, y_train,max_len = max_len)\n","dev_dataset = BuildDataset(tokenizer,  X_dev, y_dev,max_len = max_len)\n","test_dataset = BuildDataset(tokenizer,  X_test, y_test,max_len = max_len)\n","\n","# Chuan bi mo hinh\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',          \n","    num_train_epochs = 7,              \n","    per_device_train_batch_size=16,  \n","    per_device_eval_batch_size=16,\n","    warmup_steps=500,                \n","    weight_decay=0.01,\n","    learning_rate = 8e-05,\n","    no_cuda=False\n",")\n","\n","trainer = Trainer(\n","    model=model,                         \n","    args=training_args,                  \n","    train_dataset=train_dataset,         \n","    eval_dataset=dev_dataset             \n",")\n","\n","trainer.train()\n","\n","train_dataset_pred = trainer.predict(train_dataset)\n","dev_dataset_pred = trainer.predict(dev_dataset)\n","test_dataset_pred = trainer.predict(test_dataset)\n","\n","def convert_predict_label(predict_label_train):\n","    for i in range(len(predict_label_train)):\n","        for j in range(len(predict_label_train[i])):\n","            if predict_label_train[i][j] > 0.5:\n","                predict_label_train[i][j] = 1\n","            else:\n","                predict_label_train[i][j] = 0\n","    return predict_label_train\n","\n","y_train_pred = convert_predict_label(train_dataset_pred.predictions)\n","y_dev_pred = convert_predict_label(dev_dataset_pred.predictions)\n","y_test_pred = convert_predict_label(test_dataset_pred.predictions)\n","\n","y_train_true = train_dataset_pred.label_ids\n","y_dev_true = dev_dataset_pred.label_ids\n","y_test_true = test_dataset_pred.label_ids\n","\n","# Danh gia mo hinh\n","acc_train = accuracy_score(y_train_true, y_train_pred)\n","acc_dev = accuracy_score(y_dev_true, y_dev_pred)\n","acc_test = accuracy_score(y_test_true, y_test_pred)\n","f1_macro_test = f1_score(y_test_true, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test_true, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test_true, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test_true, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test_true, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test_true, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","# Lưu dự đoán\n","result = pd.DataFrame([X_test, y_test_true, y_test_pred]).T\n","result.columns = ['text', 'true_label', 'pred_label']\n","path = '/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Predict CSV/ACD_Not_Process'\n","result.to_csv(path + '/' + 'xlm-r.csv', index=False)\n","result.head()\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[11]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",\n","          index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","***** Running training *****\n","  Num examples = 7028\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3080\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3080' max='3080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3080/3080 23:43, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.293900</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.136700</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.093900</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.070000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.046900</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.031500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-2000\n","Configuration saved in ./results/checkpoint-2000/config.json\n","Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-2500\n","Configuration saved in ./results/checkpoint-2500/config.json\n","Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-3000\n","Configuration saved in ./results/checkpoint-3000/config.json\n","Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Prediction *****\n","  Num examples = 7028\n","  Batch size = 16\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='611' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [440/440 01:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["***** Running Prediction *****\n","  Num examples = 771\n","  Batch size = 16\n","***** Running Prediction *****\n","  Num examples = 1938\n","  Batch size = 16\n"],"name":"stderr"},{"output_type":"stream","text":["=================================================================================\n","Accuracy train:  0.9620091064314172\n","Accuracy dev:  0.7250324254215305\n","Accuracy test:  0.7683178534571723\n","F1 macro test:  0.8634347351268521\n","Recall macro test:  0.8565906673042948\n","Precision macro test:  0.8706323822838407\n","F1 micro test:  0.8709122203098107\n","Recall micro test:  0.8661087866108786\n","Precision micro test:  0.8757692307692307\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zTj8-w0r9KIY"},"source":["# BERT MULTILINGUAL"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d5de164eace14e13aa1b9fae08c4043b","101cc32a50084d5da86fe7991867aed5","8c018382781646f2924e2b8964c6d29a","2aa740b2b2b94f1ca88f4a2f29f2312e","0b2c5d0a5b844c6f9e0aacec9f2cb6f4","d0a51b323ffb44879292d8bab08fe3d2","848dee7e7dbf4aa1937996aa5a69fc54","909cc115f8b24298940a6d98e2453056","f2b3081f8e7942f0b4d94af1d4e1f4ea","35c7cc20bd18424b86d0477e676ef182","9808684fe55845c3a54c2ed790c88199","8500f29e8b53461d80ec46b59fc3f896","3c99912d82b74d0dbd39e92e3d495cfc","9e3fe5b0cdeb47ea9bb1d984565890e8","a54d6e87554b423bb048ef159e3d4a3e","1e302e9fc10645cb988d6c9af3d7fe0e","80cc3a3c074e424bb05783af878b2564","20953bf31aa54eb995a31ff2733ef618","c559b74c6ab049559250b6d713cbcc4a","f410661348914cdbbfd6489c778ca174","eb03bfdbf1e04baba13fceac1d6c04ab","fcbac16a9b9e4c8392a0a1ab1b478f7e","61b9521b02f5432baf21f62a1ba97b2f","fea18549e89d49c58846410daa1169fe","1b745beea706470da60978a219922286","fc5509034e8c462a8da35ee8c4d6de22","3bea8e9e14ec45d598c55daf2fd47477","5aab5fb1da04407b94e7be17c464c71a","8b62ac6d39af4756bb22b959e3ff8801","faafa8800c9e4fe29f7aa1bde82d0291","f837738530154272ae7ee47dbcd01e6c","c7e0e2b561c44ad795576112d80c0b77","67192bac395a4c9198c3853f43dfe34b","45023450f53347609a1155b588be592c","3f7178cbdf9b4a06999789541ee42f87","22de8dc868404d0d9090a1a5518239a3","b74c1b71c68448318e19861f332c04a0","3b4e3950f416414295b3cbb486e9bab1","63182909251b404586bde5af2f1541c4","ef30d9eafc6747eea72d90c6f2c42120"]},"id":"BpCDmzEu9KI0","executionInfo":{"status":"ok","timestamp":1625059000061,"user_tz":-420,"elapsed":1185314,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"7550959c-1837-4a2f-e536-b0e85d08c327"},"source":["max_len = max([len(text.split(\" \")) for text in X_train])\n","class BuildDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, tokenizer, X, y, max_len):\n","        self.tokenizer = tokenizer\n","        self.comment_text = X\n","        self.targets = y\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.comment_text)\n","\n","    def __getitem__(self, index):\n","        comment_text = str(self.comment_text[index])\n","        comment_text = \" \".join(comment_text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            comment_text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","\n","        return {\n","            'input_ids': torch.tensor(ids, dtype=torch.long),\n","            'attention_mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'labels': torch.tensor(self.targets[index], dtype=torch.float)\n","        }\n","\n","# Khai bao pre-trained\n","model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels = 12)\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n","\n","# Chuan bi data\n","train_dataset = BuildDataset(tokenizer, X_train, y_train, max_len = max_len)\n","dev_dataset = BuildDataset(tokenizer,  X_dev, y_dev, max_len = max_len)\n","test_dataset = BuildDataset(tokenizer,  X_test, y_test, max_len = max_len)\n","\n","# Chuan bi mo hinh\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',          \n","    num_train_epochs = 7,              \n","    per_device_train_batch_size=16,  \n","    per_device_eval_batch_size=16,\n","    warmup_steps=500,                \n","    weight_decay=0.01,\n","    learning_rate = 8e-05,\n","    no_cuda=False\n",")\n","\n","trainer = Trainer(\n","    model=model,                         \n","    args=training_args,                  \n","    train_dataset=train_dataset,         \n","    eval_dataset=dev_dataset             \n",")\n","\n","trainer.train()\n","\n","train_dataset_pred = trainer.predict(train_dataset)\n","dev_dataset_pred = trainer.predict(dev_dataset)\n","test_dataset_pred = trainer.predict(test_dataset)\n","\n","def convert_predict_label(predict_label_train):\n","    for i in range(len(predict_label_train)):\n","        for j in range(len(predict_label_train[i])):\n","            if predict_label_train[i][j] > 0.5:\n","                predict_label_train[i][j] = 1\n","            else:\n","                predict_label_train[i][j] = 0\n","    return predict_label_train\n","\n","y_train_pred = convert_predict_label(train_dataset_pred.predictions)\n","y_dev_pred = convert_predict_label(dev_dataset_pred.predictions)\n","y_test_pred = convert_predict_label(test_dataset_pred.predictions)\n","\n","y_train_true = train_dataset_pred.label_ids\n","y_dev_true = dev_dataset_pred.label_ids\n","y_test_true = test_dataset_pred.label_ids\n","\n","# Danh gia mo hinh\n","acc_train = accuracy_score(y_train_true, y_train_pred)\n","acc_dev = accuracy_score(y_dev_true, y_dev_pred)\n","acc_test = accuracy_score(y_test_true, y_test_pred)\n","f1_macro_test = f1_score(y_test_true, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test_true, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test_true, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test_true, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test_true, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test_true, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","# Lưu dự đoán\n","result = pd.DataFrame([X_test, y_test_true, y_test_pred]).T\n","result.columns = ['text', 'true_label', 'pred_label']\n","path = '/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Predict CSV/ACD_Not_Process'\n","result.to_csv(path + '/' + 'bert-multi.csv', index=False)\n","result.head()\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[12]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Process/ACD_Not_Process.csv\",\n","          index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5de164eace14e13aa1b9fae08c4043b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2b3081f8e7942f0b4d94af1d4e1f4ea","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80cc3a3c074e424bb05783af878b2564","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b745beea706470da60978a219922286","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67192bac395a4c9198c3853f43dfe34b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1961828.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["***** Running training *****\n","  Num examples = 7028\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3080\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3080' max='3080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3080/3080 18:07, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.285800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.146800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.098500</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.065900</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.040800</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.023800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-2000\n","Configuration saved in ./results/checkpoint-2000/config.json\n","Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-2500\n","Configuration saved in ./results/checkpoint-2500/config.json\n","Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-3000\n","Configuration saved in ./results/checkpoint-3000/config.json\n","Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Prediction *****\n","  Num examples = 7028\n","  Batch size = 16\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='611' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [440/440 01:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["***** Running Prediction *****\n","  Num examples = 771\n","  Batch size = 16\n","***** Running Prediction *****\n","  Num examples = 1938\n","  Batch size = 16\n"],"name":"stderr"},{"output_type":"stream","text":["=================================================================================\n","Accuracy train:  0.9770916334661355\n","Accuracy dev:  0.695201037613489\n","Accuracy test:  0.7239422084623323\n","F1 macro test:  0.8331421581095776\n","Recall macro test:  0.8240536115326026\n","Precision macro test:  0.8436705680372025\n","F1 micro test:  0.8456813819577735\n","Recall micro test:  0.8379612019779383\n","Precision micro test:  0.8535451375435877\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f3hAwsvUB60W"},"source":["# BERT FPTAI/vibert-base-cased\n","\n"]},{"cell_type":"code","metadata":{"id":"4-4o5FZCqbqx","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4b2789d5b1c1441c93cfc51a7d6f3715","458cd8ff00054aa2b5494d0fc1f205f6","d577b6dccab04f2590652f582e95af45","72317bf812354443b095f903fd40053e","abc4e38cb8e742a4a6fb7c8dbc1bcd53","070a2f2614da40638357f3d672960cfc","270e00616f6042f69be29e9f7ae3b793","0c09c07eec9149838b36ce460ef3fe09","ad22718cc81540828304f8eaaa2745f9","353b390f87494538af63332828c83942","074f7670412948baa84391ad4cb3190c","7cdf6b52c33447399d08082b771340f4","c32f53ee020e46f89d68b8c177b7bae2","444784ccef004664baa27e2b529c0edf","4547660b5be64960aad6e2d7b8888c7b","97a0a9e0d5d34e89afcf8d03631bb81b","57600fabe0e841ce86e10ef35572d25d","4d01ac54670f49c790fb2c2020f0dfa0","7cfd5be3cf3e4756b519c4365619d00d","1b6225bedc39450eb3703d44124d0659","ab7ee9b99a3c4149980d96c2a2225ddf","52750ff035f04df9ae93cc51ae68d9f5","12e4f29a59144cd4af0fe7cf026f9ae6","2afebcd02ebd442480fab37213e06308"]},"executionInfo":{"status":"ok","timestamp":1624976377887,"user_tz":-420,"elapsed":1069264,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"63ebe95f-f9b7-4d4d-8f90-3e790d8f2759"},"source":["class BuildDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, tokenizer, X, y, max_len):\n","        self.tokenizer = tokenizer\n","        self.comment_text = X\n","        self.targets = y\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.comment_text)\n","\n","    def __getitem__(self, index):\n","        comment_text = str(self.comment_text[index])\n","        comment_text = \" \".join(comment_text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            comment_text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","\n","        return {\n","            'input_ids': torch.tensor(ids, dtype=torch.long),\n","            'attention_mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'labels': torch.tensor(self.targets[index], dtype=torch.float)\n","        }\n","\n","# Khai bao pre-trained\n","model = AutoModelForSequenceClassification.from_pretrained('FPTAI/vibert-base-cased', num_labels = 12)\n","tokenizer = AutoTokenizer.from_pretrained('FPTAI/vibert-base-cased')\n","\n","# Chuan bi data\n","train_dataset = BuildDataset(tokenizer, X_train, y_train,max_len = max_len)\n","dev_dataset = BuildDataset(tokenizer,  X_dev, y_dev,max_len = max_len)\n","test_dataset = BuildDataset(tokenizer,  X_test, y_test,max_len = max_len)\n","\n","# Chuan bi mo hinh\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',          \n","    num_train_epochs = 7,              \n","    per_device_train_batch_size=16,  \n","    per_device_eval_batch_size=16,\n","    warmup_steps=500,                \n","    weight_decay=0.01,\n","    no_cuda=False\n",")\n","\n","trainer = Trainer(\n","    model=model,                         \n","    args=training_args,                  \n","    train_dataset=train_dataset,         \n","    eval_dataset=dev_dataset             \n",")\n","\n","trainer.train()\n","\n","train_dataset_pred = trainer.predict(train_dataset)\n","dev_dataset_pred = trainer.predict(dev_dataset)\n","test_dataset_pred = trainer.predict(test_dataset)\n","\n","def convert_predict_label(predict_label_train):\n","    for i in range(len(predict_label_train)):\n","        for j in range(len(predict_label_train[i])):\n","            if predict_label_train[i][j] > 0.5:\n","                predict_label_train[i][j] = 1\n","            else:\n","                predict_label_train[i][j] = 0\n","    return predict_label_train\n","\n","y_train_pred = convert_predict_label(train_dataset_pred.predictions)\n","y_dev_pred = convert_predict_label(dev_dataset_pred.predictions)\n","y_test_pred = convert_predict_label(test_dataset_pred.predictions)\n","\n","y_train_true = train_dataset_pred.label_ids\n","y_dev_true = dev_dataset_pred.label_ids\n","y_test_true = test_dataset_pred.label_ids\n","\n","# Danh gia mo hinh\n","acc_train = accuracy_score(y_train_true, y_train_pred)\n","acc_dev = accuracy_score(y_dev_true, y_dev_pred)\n","acc_test = accuracy_score(y_test_true, y_test_pred)\n","f1_macro_test = f1_score(y_test_true, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test_true, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test_true, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test_true, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test_true, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test_true, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","# Lưu dự đoán\n","result = pd.DataFrame([X_test, y_test_true, y_test_pred]).T\n","result.columns = ['text', 'true_label', 'pred_label']\n","path = '/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Predict CSV/ACD_Not_Process'\n","result.to_csv(path + '/' + 'vibert-base-cased.csv', index=False)\n","result.head()\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[12]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",\n","          index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_oj7h7rw\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b2789d5b1c1441c93cfc51a7d6f3715","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1403.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/ac830dbe95fda61dfb6f6479706d481dd2c7c2ed4b9064b5fb56ecc53f0ed2fa.7d942d26e554f7243a0055f745a11844b215e58ac9e8a5dc60dbf1ec3c474a71\n","creating metadata file for /root/.cache/huggingface/transformers/ac830dbe95fda61dfb6f6479706d481dd2c7c2ed4b9064b5fb56ecc53f0ed2fa.7d942d26e554f7243a0055f745a11844b215e58ac9e8a5dc60dbf1ec3c474a71\n","loading configuration file https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ac830dbe95fda61dfb6f6479706d481dd2c7c2ed4b9064b5fb56ecc53f0ed2fa.7d942d26e554f7243a0055f745a11844b215e58ac9e8a5dc60dbf1ec3c474a71\n","Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.8.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 38168\n","}\n","\n","https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp8c8on5r5\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad22718cc81540828304f8eaaa2745f9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=581243664.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/3b6bb982f8f72144ec767bb8989b8c461701c754926d55b2de1246236b033a41.2008df591695a6a2b7c9fecb024177ee92349c5d089f9063ea0413bbb07c3e5a\n","creating metadata file for /root/.cache/huggingface/transformers/3b6bb982f8f72144ec767bb8989b8c461701c754926d55b2de1246236b033a41.2008df591695a6a2b7c9fecb024177ee92349c5d089f9063ea0413bbb07c3e5a\n","loading weights file https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3b6bb982f8f72144ec767bb8989b8c461701c754926d55b2de1246236b033a41.2008df591695a6a2b7c9fecb024177ee92349c5d089f9063ea0413bbb07c3e5a\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at FPTAI/vibert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at FPTAI/vibert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ac830dbe95fda61dfb6f6479706d481dd2c7c2ed4b9064b5fb56ecc53f0ed2fa.7d942d26e554f7243a0055f745a11844b215e58ac9e8a5dc60dbf1ec3c474a71\n","Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.8.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 38168\n","}\n","\n","https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpigjqja5q\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57600fabe0e841ce86e10ef35572d25d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=254703.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/c155f922cc460ace2ddcb1485f2768b33a43a86e4c6fea76677b773dfff3b232.3d46541cba3b17f4b15f094a380f7c83603387b794207b9b1f1b9dfd58b1d1c4\n","creating metadata file for /root/.cache/huggingface/transformers/c155f922cc460ace2ddcb1485f2768b33a43a86e4c6fea76677b773dfff3b232.3d46541cba3b17f4b15f094a380f7c83603387b794207b9b1f1b9dfd58b1d1c4\n","loading file https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/c155f922cc460ace2ddcb1485f2768b33a43a86e4c6fea76677b773dfff3b232.3d46541cba3b17f4b15f094a380f7c83603387b794207b9b1f1b9dfd58b1d1c4\n","loading file https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/FPTAI/vibert-base-cased/resolve/main/tokenizer_config.json from cache at None\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running training *****\n","  Num examples = 7028\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3080\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3080' max='3080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3080/3080 16:22, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.343500</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.156600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.094900</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.055600</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.033300</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.021400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-2000\n","Configuration saved in ./results/checkpoint-2000/config.json\n","Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-2500\n","Configuration saved in ./results/checkpoint-2500/config.json\n","Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-3000\n","Configuration saved in ./results/checkpoint-3000/config.json\n","Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Prediction *****\n","  Num examples = 7028\n","  Batch size = 16\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='611' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [440/440 01:06]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["***** Running Prediction *****\n","  Num examples = 771\n","  Batch size = 16\n","***** Running Prediction *****\n","  Num examples = 1938\n","  Batch size = 16\n"],"name":"stderr"},{"output_type":"stream","text":["=================================================================================\n","Accuracy train:  0.9830677290836654\n","Accuracy dev:  0.6809338521400778\n","Accuracy test:  0.7074303405572755\n","F1 macro test:  0.8174296523600089\n","Recall macro test:  0.7895521858588829\n","Precision macro test:  0.8491700860796292\n","F1 micro test:  0.8312195121951219\n","Recall micro test:  0.8101939901103081\n","Precision micro test:  0.8533653846153846\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2gVKfe-hCF7z"},"source":["# BERT vinai/phobert-base"]},{"cell_type":"code","metadata":{"id":"4wfCaXMjFnBd","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1624976432514,"user_tz":-420,"elapsed":54356,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"f40300d8-4c67-4a3b-8fb5-6a4c7e67fa57"},"source":["# VNCoreNLP tách từ\n","!pip install deplacy vncorenlp\n","!test -d VnCoreNLP || git clone --depth=1 https://github.com/vncorenlp/VnCoreNLP\n","from vncorenlp import VnCoreNLP\n","vncorenlp = VnCoreNLP(\"VnCoreNLP/VnCoreNLP-1.1.1.jar\",annotators=\"wseg\")\n","def vncore_tokenize(document):\n","    l = vncorenlp.tokenize(document)[0]\n","    document = ''\n","    for i in range(len(l)):\n","        document += l[i] + ' '\n","    document = document[:-1]\n","    return document\n","\n","def text_preprocessing(X):\n","    for i in range(len(X)):\n","        X[i] = vncore_tokenize(X[i])\n","    return X\n","\n","X_train = text_preprocessing(X_train)\n","X_dev = text_preprocessing(X_dev)\n","X_test = text_preprocessing(X_test)\n","\n","# Độ dài cmt\n","def plot_number_word(X, name):\n","    l = []\n","    for i in range(len(X)):\n","        l.append(len(X[i].split()))\n","    plt.figure(figsize = (15, 2))\n","    sns.countplot(l)\n","    plt.title(\"Number of words in comment in \" + name + ' dataset.')\n","    plt.xlabel(\"Number of words\")\n","    plt.ylabel(\"Frequency\")\n","    plt.show()\n","\n","plot_number_word(X_train, 'train')\n","plot_number_word(X_dev, 'dev')\n","plot_number_word(X_test, 'test')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting deplacy\n","  Downloading https://files.pythonhosted.org/packages/6d/93/875bac95a20aed7814c86c5807c88e709ee8228091d7b732b99d081b1da0/deplacy-1.9.8-py3-none-any.whl\n","Collecting vncorenlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.7MB 36.2MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vncorenlp) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2.10)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp37-none-any.whl size=2645952 sha256=d2a2717d4c74a28b2292d5f834e844014dc3dd21b7f40a63db93509a648a9cab\n","  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n","Successfully built vncorenlp\n","Installing collected packages: deplacy, vncorenlp\n","Successfully installed deplacy-1.9.8 vncorenlp-1.0.3\n","Cloning into 'VnCoreNLP'...\n","remote: Enumerating objects: 54, done.\u001b[K\n","remote: Counting objects: 100% (54/54), done.\u001b[K\n","remote: Compressing objects: 100% (45/45), done.\u001b[K\n","remote: Total 54 (delta 1), reused 41 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (54/54), done.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1080x144 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1080x144 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1080x144 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"14VIzJ65pcaq","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d245d17206f840f0bb7401aef37f4e6c","31eef4459e104536aec796ea09be9a49","a0956a6f0ef14745ae22165a8a47df43","fb490e5a97df4e82b5ebff2d4d3bc014","51d67c00686b4386b3d0bd6485b52c3a","92a1c3ca15c24882bb04be49b3fb34a5","5753d14430524a61addb19d5ee1d70fa","a916dff565804e0fb11940fe838d2ead","7094a2be6b174e8f98d27d34fca2b462","d47944c684674afca2c47361f2a88060","30ddb1112fb24abe968387c198a62a4a","3a71f33cc8c642d5902e42e99619e18a","d9ff860cfd1b416fad11e6ed2262ac42","1e1a075005c54f8181ce026cc68c5342","26348156ca8c4b07b56156ed863ec236","7dd8674cbe084d04bb9ec06c35b1660b","36518c63379f4b7ea87f5978472410c0","e349d8b8fb454e66be5c005389aa0202","31633536071646478d235ea1ce257a2e","701575875e924f0fa523a6f728df5b2e","0b78ff6ab4144db68092aa34bf4334b3","5a0319354e8d40f5bd1c53a872d27c95","38b57d9f12f24466a526bb7e0d79dd0b","c90df9743e234a198b9a6da376e495c4","8b22b22fc26f4824a9e7c5abf4861e19","aaaad4f481c04bef8a2bbefe70ca1d96","202b60fb9903403095f09f2c9c1e0a0c","36417ee4b07840839365e5196710153a","24e761703bb24ef3afff084e71969972","75862d3ac7874382aeddfcf888af44b8","d1fd8d0616e64dc7863a3ec72de9a2fc","c68c1f1b4ce748e2bd019dcc16a28491"]},"executionInfo":{"status":"ok","timestamp":1624977595562,"user_tz":-420,"elapsed":1163054,"user":{"displayName":"Huy Lam Gia","photoUrl":"","userId":"16757804681341342086"}},"outputId":"52ad9e99-5301-45bc-97e9-008c1c7f36c9"},"source":["max_len = max([len(text.split(\" \")) for text in X_train])\n","class BuildDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, tokenizer, X, y, max_len):\n","        self.tokenizer = tokenizer\n","        self.comment_text = X\n","        self.targets = y\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.comment_text)\n","\n","    def __getitem__(self, index):\n","        comment_text = str(self.comment_text[index])\n","        comment_text = \" \".join(comment_text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            comment_text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","\n","        return {\n","            'input_ids': torch.tensor(ids, dtype=torch.long),\n","            'attention_mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'labels': torch.tensor(self.targets[index], dtype=torch.float)\n","        }\n","\n","# Khai bao pre-trained\n","model = AutoModelForSequenceClassification.from_pretrained('vinai/phobert-base', num_labels = 12)\n","tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base')\n","\n","# Chuan bi data\n","train_dataset = BuildDataset(tokenizer, X_train, y_train,max_len = max_len)\n","dev_dataset = BuildDataset(tokenizer,  X_dev, y_dev,max_len = max_len)\n","test_dataset = BuildDataset(tokenizer,  X_test, y_test,max_len = max_len)\n","\n","\n","# Chuan bi mo hinh\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',          \n","    num_train_epochs = 7,              \n","    per_device_train_batch_size=16,  \n","    per_device_eval_batch_size=16,\n","    warmup_steps=500,                \n","    weight_decay=0.01,\n","    no_cuda=False\n",")\n","\n","trainer = Trainer(\n","    model=model,                         \n","    args=training_args,                  \n","    train_dataset=train_dataset,         \n","    eval_dataset=dev_dataset             \n",")\n","\n","trainer.train()\n","\n","train_dataset_pred = trainer.predict(train_dataset)\n","dev_dataset_pred = trainer.predict(dev_dataset)\n","test_dataset_pred = trainer.predict(test_dataset)\n","\n","def convert_predict_label(predict_label_train):\n","    for i in range(len(predict_label_train)):\n","        for j in range(len(predict_label_train[i])):\n","            if predict_label_train[i][j] > 0.5:\n","                predict_label_train[i][j] = 1\n","            else:\n","                predict_label_train[i][j] = 0\n","    return predict_label_train\n","\n","y_train_pred = convert_predict_label(train_dataset_pred.predictions)\n","y_dev_pred = convert_predict_label(dev_dataset_pred.predictions)\n","y_test_pred = convert_predict_label(test_dataset_pred.predictions)\n","\n","y_train_true = train_dataset_pred.label_ids\n","y_dev_true = dev_dataset_pred.label_ids\n","y_test_true = test_dataset_pred.label_ids\n","\n","# Danh gia mo hinh\n","acc_train = accuracy_score(y_train_true, y_train_pred)\n","acc_dev = accuracy_score(y_dev_true, y_dev_pred)\n","acc_test = accuracy_score(y_test_true, y_test_pred)\n","f1_macro_test = f1_score(y_test_true, y_test_pred, average='macro')\n","recall_macro_test = recall_score(y_test_true, y_test_pred, average='macro')\n","precision_macro_test = precision_score(y_test_true, y_test_pred, average='macro')\n","f1_micro_test = f1_score(y_test_true, y_test_pred, average='micro')\n","recall_micro_test = recall_score(y_test_true, y_test_pred, average='micro')\n","precision_micro_test = precision_score(y_test_true, y_test_pred, average='micro')\n","print('=================================================================================')\n","print('Accuracy train: ', acc_train)\n","print('Accuracy dev: ', acc_dev)\n","print('Accuracy test: ', acc_test)\n","print('F1 macro test: ', f1_macro_test)\n","print('Recall macro test: ', recall_macro_test)\n","print('Precision macro test: ', precision_macro_test)\n","print('F1 micro test: ', f1_micro_test)\n","print('Recall micro test: ', recall_micro_test)\n","print('Precision micro test: ', precision_micro_test)\n","\n","# Lưu dự đoán\n","result = pd.DataFrame([X_test, y_test_true, y_test_pred]).T\n","result.columns = ['text', 'true_label', 'pred_label']\n","path = '/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Predict CSV/ACD_Not_Process'\n","result.to_csv(path + '/' + 'phoBert.csv', index=False)\n","result.head()\n","\n","#Lưu record\n","df = pd.DataFrame({\"Model\": [model_name[13]],\n","                   \"ACC_TRAIN\": [acc_train],\n","                   \"ACC_DEV\": [acc_dev],\n","                   \"ACC_TEST\": [acc_test],\n","                   \"PRECISION-MACRO\": [precision_macro_test],\n","                   \"RECALL-MACRO\":[recall_macro_test],\n","                    \"F1-MACRO\": [f1_macro_test],\n","                   \"PRECISION-MICRO\": [precision_micro_test],\n","                   \"RECALL-MICRO\":[recall_micro_test],\n","                   \"F1-MICRO\": [f1_micro_test]})\n","df.to_csv(\"/content/drive/MyDrive/NLP for Data Science/NLP_Project/Source Code/Evaluate/ACD_Not_Process/ACD_Not_Process.csv\",\n","          index = None, header = False, mode = \"a\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["https://huggingface.co/vinai/phobert-base/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpknjci3xk\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d245d17206f840f0bb7401aef37f4e6c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=557.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/vinai/phobert-base/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/a596f267f08b7158c7ab6300b1bf98eb6e1b05e6bcb0d7c18a8070364ee3011b.bbe27b2cac909b2279c83792c2d2b6f159f0a95f5d1c1eb66451da1c89a53609\n","creating metadata file for /root/.cache/huggingface/transformers/a596f267f08b7158c7ab6300b1bf98eb6e1b05e6bcb0d7c18a8070364ee3011b.bbe27b2cac909b2279c83792c2d2b6f159f0a95f5d1c1eb66451da1c89a53609\n","loading configuration file https://huggingface.co/vinai/phobert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a596f267f08b7158c7ab6300b1bf98eb6e1b05e6bcb0d7c18a8070364ee3011b.bbe27b2cac909b2279c83792c2d2b6f159f0a95f5d1c1eb66451da1c89a53609\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"transformers_version\": \"4.8.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","https://huggingface.co/vinai/phobert-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpifxh9nb9\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7094a2be6b174e8f98d27d34fca2b462","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=542923308.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/vinai/phobert-base/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/8363542cfd9e2bad1a9a618e87ea1153d84819a3ae581cff0816a2c1f610f433.42a5e558f15db4cc3af338445707272b8f7545df78efdc125d3fd51025b22d85\n","creating metadata file for /root/.cache/huggingface/transformers/8363542cfd9e2bad1a9a618e87ea1153d84819a3ae581cff0816a2c1f610f433.42a5e558f15db4cc3af338445707272b8f7545df78efdc125d3fd51025b22d85\n","loading weights file https://huggingface.co/vinai/phobert-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/8363542cfd9e2bad1a9a618e87ea1153d84819a3ae581cff0816a2c1f610f433.42a5e558f15db4cc3af338445707272b8f7545df78efdc125d3fd51025b22d85\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/vinai/phobert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a596f267f08b7158c7ab6300b1bf98eb6e1b05e6bcb0d7c18a8070364ee3011b.bbe27b2cac909b2279c83792c2d2b6f159f0a95f5d1c1eb66451da1c89a53609\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"PhobertTokenizer\",\n","  \"transformers_version\": \"4.8.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","https://huggingface.co/vinai/phobert-base/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpsoxxfsqw\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36518c63379f4b7ea87f5978472410c0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=895321.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/vinai/phobert-base/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/970c6224b2713c8b52a7bcfc4d5a951c9bb88302e4523388b50f28284e87ac44.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","creating metadata file for /root/.cache/huggingface/transformers/970c6224b2713c8b52a7bcfc4d5a951c9bb88302e4523388b50f28284e87ac44.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","https://huggingface.co/vinai/phobert-base/resolve/main/bpe.codes not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpxzg930kz\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b22b22fc26f4824a9e7c5abf4861e19","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1135173.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["storing https://huggingface.co/vinai/phobert-base/resolve/main/bpe.codes in cache at /root/.cache/huggingface/transformers/f3a66ae0a78d1a53b3eb99e31837d0d8e2f684a2dcc1f52f75fd36873e3d79de.301ac8958de708ddcea8500d9acbe6261dba391d249c98dcda1e49dbbff870dd\n","creating metadata file for /root/.cache/huggingface/transformers/f3a66ae0a78d1a53b3eb99e31837d0d8e2f684a2dcc1f52f75fd36873e3d79de.301ac8958de708ddcea8500d9acbe6261dba391d249c98dcda1e49dbbff870dd\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["loading file https://huggingface.co/vinai/phobert-base/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/970c6224b2713c8b52a7bcfc4d5a951c9bb88302e4523388b50f28284e87ac44.26ba0c8945e559c68d0bc35d24fea16f5463a49fe8f134e0c32261d590b577fa\n","loading file https://huggingface.co/vinai/phobert-base/resolve/main/bpe.codes from cache at /root/.cache/huggingface/transformers/f3a66ae0a78d1a53b3eb99e31837d0d8e2f684a2dcc1f52f75fd36873e3d79de.301ac8958de708ddcea8500d9acbe6261dba391d249c98dcda1e49dbbff870dd\n","loading file https://huggingface.co/vinai/phobert-base/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/vinai/phobert-base/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/vinai/phobert-base/resolve/main/tokenizer_config.json from cache at None\n","loading file https://huggingface.co/vinai/phobert-base/resolve/main/tokenizer.json from cache at None\n","Adding <mask> to the vocabulary\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running training *****\n","  Num examples = 7028\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3080\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3080' max='3080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3080/3080 18:05, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.340300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.124500</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.069500</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.042800</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.027100</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.018700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-2000\n","Configuration saved in ./results/checkpoint-2000/config.json\n","Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-2500\n","Configuration saved in ./results/checkpoint-2500/config.json\n","Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-3000\n","Configuration saved in ./results/checkpoint-3000/config.json\n","Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Prediction *****\n","  Num examples = 7028\n","  Batch size = 16\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='611' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [440/440 01:02]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["***** Running Prediction *****\n","  Num examples = 771\n","  Batch size = 16\n","***** Running Prediction *****\n","  Num examples = 1938\n","  Batch size = 16\n"],"name":"stderr"},{"output_type":"stream","text":["=================================================================================\n","Accuracy train:  0.9839214570290268\n","Accuracy dev:  0.767833981841764\n","Accuracy test:  0.782249742002064\n","F1 macro test:  0.869136809028082\n","Recall macro test:  0.8595349199643175\n","Precision macro test:  0.8794879299586028\n","F1 micro test:  0.8763399693721287\n","Recall micro test:  0.8706732597945988\n","Precision micro test:  0.8820809248554913\n"],"name":"stdout"}]}]}